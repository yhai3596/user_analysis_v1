import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import folium
from streamlit_folium import st_folium
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from utils.visualizer import UserBehaviorVisualizer, create_dashboard_metrics, display_metrics_cards
from utils.cache_manager import cache_data
from config.settings import get_config

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="åœ°ç†è¡Œä¸ºåˆ†æ",
    page_icon="ğŸ—ºï¸",
    layout="wide"
)

class GeoAnalyzer:
    """åœ°ç†è¡Œä¸ºåˆ†æå™¨"""
    
    def __init__(self):
        self.visualizer = UserBehaviorVisualizer()
        self.viz_config = get_config('viz')
        
        # ä¸­å›½ä¸»è¦åŸå¸‚åæ ‡ï¼ˆç¤ºä¾‹æ•°æ®ï¼‰
        self.city_coordinates = {
            'åŒ—äº¬': [39.9042, 116.4074],
            'ä¸Šæµ·': [31.2304, 121.4737],
            'å¹¿å·': [23.1291, 113.2644],
            'æ·±åœ³': [22.5431, 114.0579],
            'æ­å·': [30.2741, 120.1551],
            'å—äº¬': [32.0603, 118.7969],
            'æ­¦æ±‰': [30.5928, 114.3055],
            'æˆéƒ½': [30.5728, 104.0668],
            'è¥¿å®‰': [34.3416, 108.9398],
            'é‡åº†': [29.5630, 106.5516],
            'å¤©æ´¥': [39.3434, 117.3616],
            'è‹å·': [31.2989, 120.5853],
            'é’å²›': [36.0986, 120.3719],
            'é•¿æ²™': [28.2282, 112.9388],
            'å¤§è¿': [38.9140, 121.6147],
            'å¦é—¨': [24.4798, 118.0894],
            'æ— é”¡': [31.4912, 120.3124],
            'ç¦å·': [26.0745, 119.2965],
            'æµå—': [36.6512, 117.1201],
            'å®æ³¢': [29.8683, 121.5440]
        }
    
    @cache_data(ttl=1800)
    def analyze_geographic_distribution(self, df: pd.DataFrame) -> dict:
        """åˆ†æåœ°ç†åˆ†å¸ƒ"""
        analysis = {}
        
        # çœä»½åˆ†å¸ƒ
        if 'æ³¨å†Œçœä»½' in df.columns:
            province_dist = df['æ³¨å†Œçœä»½'].value_counts()
            analysis['province_distribution'] = province_dist.to_dict()
            analysis['province_stats'] = {
                'total_provinces': len(province_dist),
                'top_province': province_dist.index[0],
                'top_province_ratio': province_dist.iloc[0] / len(df) * 100
            }
        
        # åŸå¸‚åˆ†å¸ƒ
        if 'æ³¨å†ŒåŸå¸‚' in df.columns:
            city_dist = df['æ³¨å†ŒåŸå¸‚'].value_counts()
            analysis['city_distribution'] = city_dist.to_dict()
            analysis['city_stats'] = {
                'total_cities': len(city_dist),
                'top_city': city_dist.index[0],
                'top_city_ratio': city_dist.iloc[0] / len(df) * 100
            }
        
        # åœ°ç†é›†ä¸­åº¦åˆ†æ
        if 'æ³¨å†Œçœä»½' in df.columns:
            # è®¡ç®—åŸºå°¼ç³»æ•°ï¼ˆåœ°ç†é›†ä¸­åº¦ï¼‰
            province_counts = df['æ³¨å†Œçœä»½'].value_counts().values
            province_counts_sorted = np.sort(province_counts)
            n = len(province_counts_sorted)
            cumsum = np.cumsum(province_counts_sorted)
            gini = (2 * np.sum((np.arange(1, n + 1) * province_counts_sorted))) / (n * np.sum(province_counts_sorted)) - (n + 1) / n
            analysis['geographic_concentration'] = {
                'gini_coefficient': gini,
                'concentration_level': 'high' if gini > 0.6 else 'medium' if gini > 0.4 else 'low'
            }
        
        return analysis
    
    @cache_data(ttl=1800)
    def analyze_regional_behavior(self, df: pd.DataFrame) -> dict:
        """åˆ†æåŒºåŸŸè¡Œä¸ºå·®å¼‚"""
        analysis = {}
        
        if 'æ³¨å†Œçœä»½' in df.columns:
            # æŒ‰çœä»½åˆ†ç»„åˆ†æè¡Œä¸ºæŒ‡æ ‡
            behavior_metrics = ['å¾®åšæ•°', 'å…³æ³¨æ•°', 'ç²‰ä¸æ•°']
            available_metrics = [m for m in behavior_metrics if m in df.columns]
            
            if available_metrics:
                province_behavior = df.groupby('æ³¨å†Œçœä»½')[available_metrics].agg({
                    metric: ['mean', 'median', 'std', 'count'] for metric in available_metrics
                }).round(2)
                
                analysis['province_behavior'] = province_behavior.to_dict()
                
                # æ‰¾å‡ºæœ€æ´»è·ƒçš„çœä»½
                if 'å¾®åšæ•°' in available_metrics:
                    most_active_province = df.groupby('æ³¨å†Œçœä»½')['å¾®åšæ•°'].mean().idxmax()
                    analysis['most_active_province'] = most_active_province
                
                # æ‰¾å‡ºå½±å“åŠ›æœ€å¤§çš„çœä»½
                if 'ç²‰ä¸æ•°' in available_metrics:
                    most_influential_province = df.groupby('æ³¨å†Œçœä»½')['ç²‰ä¸æ•°'].mean().idxmax()
                    analysis['most_influential_province'] = most_influential_province
        
        return analysis
    
    @cache_data(ttl=1800)
    def create_geographic_heatmap_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºåœ°ç†çƒ­åŠ›å›¾æ•°æ®"""
        if 'æ³¨å†ŒåŸå¸‚' not in df.columns:
            return pd.DataFrame()
        
        # ç»Ÿè®¡åŸå¸‚ç”¨æˆ·æ•°
        city_counts = df['æ³¨å†ŒåŸå¸‚'].value_counts().reset_index()
        city_counts.columns = ['city', 'user_count']
        
        # æ·»åŠ åæ ‡ä¿¡æ¯
        city_counts['lat'] = city_counts['city'].map(lambda x: self.city_coordinates.get(x, [None, None])[0])
        city_counts['lon'] = city_counts['city'].map(lambda x: self.city_coordinates.get(x, [None, None])[1])
        
        # è¿‡æ»¤æ‰æ²¡æœ‰åæ ‡çš„åŸå¸‚
        city_counts = city_counts.dropna(subset=['lat', 'lon'])
        
        return city_counts
    
    def create_folium_map(self, heatmap_data: pd.DataFrame) -> folium.Map:
        """åˆ›å»ºFoliumåœ°å›¾"""
        # åˆ›å»ºä»¥ä¸­å›½ä¸ºä¸­å¿ƒçš„åœ°å›¾
        m = folium.Map(
            location=[35.0, 105.0],  # ä¸­å›½ä¸­å¿ƒåæ ‡
            zoom_start=5,
            tiles='OpenStreetMap'
        )
        
        if not heatmap_data.empty:
            # æ·»åŠ çƒ­åŠ›å›¾å±‚
            from folium.plugins import HeatMap
            
            heat_data = [[row['lat'], row['lon'], row['user_count']] 
                        for idx, row in heatmap_data.iterrows()]
            
            HeatMap(heat_data, radius=15, blur=10, gradient={
                0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 1: 'red'
            }).add_to(m)
            
            # æ·»åŠ åŸå¸‚æ ‡è®°
            for idx, row in heatmap_data.head(10).iterrows():  # åªæ˜¾ç¤ºå‰10ä¸ªåŸå¸‚
                folium.CircleMarker(
                    location=[row['lat'], row['lon']],
                    radius=min(row['user_count'] / 10, 20),  # æ ¹æ®ç”¨æˆ·æ•°è°ƒæ•´å¤§å°
                    popup=f"{row['city']}: {row['user_count']}äºº",
                    color='red',
                    fill=True,
                    fillColor='red',
                    fillOpacity=0.6
                ).add_to(m)
        
        return m

def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ—ºï¸ åœ°ç†è¡Œä¸ºåˆ†æ")
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦å·²åŠ è½½
    if 'data_loaded' not in st.session_state or not st.session_state.data_loaded:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¸»é¡µåŠ è½½æ•°æ®")
        st.stop()
    
    # è·å–æ•°æ®
    df = st.session_state.get('filtered_data', st.session_state.current_data)
    
    # ç¡®ä¿æ•°æ®ä¸ä¸ºNone
    if df is None:
        st.error("âŒ æ•°æ®è·å–å¤±è´¥ï¼Œè¯·è¿”å›ä¸»é¡µé‡æ–°åŠ è½½æ•°æ®")
        st.stop()
    
    analyzer = GeoAnalyzer()
    
    # ä¾§è¾¹æ æ§åˆ¶
    st.sidebar.subheader("ğŸ—ºï¸ åˆ†æé€‰é¡¹")
    
    analysis_type = st.sidebar.selectbox(
        "é€‰æ‹©åˆ†æç±»å‹",
        ["åœ°ç†åˆ†å¸ƒæ¦‚è§ˆ", "åŒºåŸŸè¡Œä¸ºå·®å¼‚", "åœ°ç†çƒ­åŠ›å›¾", "åŸå¸‚æ’è¡Œæ¦œ", "åœ°ç†æ´å¯ŸæŠ¥å‘Š"]
    )
    
    # æ•°æ®æ¦‚è§ˆ
    st.subheader("ğŸ“ˆ æ•°æ®æ¦‚è§ˆ")
    metrics = create_dashboard_metrics(df)
    display_metrics_cards(metrics)
    
    # æ ¹æ®é€‰æ‹©çš„åˆ†æç±»å‹æ˜¾ç¤ºå†…å®¹
    if analysis_type == "åœ°ç†åˆ†å¸ƒæ¦‚è§ˆ":
        show_geographic_overview(df, analyzer)
    elif analysis_type == "åŒºåŸŸè¡Œä¸ºå·®å¼‚":
        show_regional_behavior(df, analyzer)
    elif analysis_type == "åœ°ç†çƒ­åŠ›å›¾":
        show_geographic_heatmap(df, analyzer)
    elif analysis_type == "åŸå¸‚æ’è¡Œæ¦œ":
        show_city_rankings(df, analyzer)
    elif analysis_type == "åœ°ç†æ´å¯ŸæŠ¥å‘Š":
        show_geographic_insights(df, analyzer)

def show_geographic_overview(df: pd.DataFrame, analyzer: GeoAnalyzer):
    """æ˜¾ç¤ºåœ°ç†åˆ†å¸ƒæ¦‚è§ˆ"""
    st.subheader("ğŸŒ åœ°ç†åˆ†å¸ƒæ¦‚è§ˆ")
    
    # åˆ†æåœ°ç†åˆ†å¸ƒ
    geo_analysis = analyzer.analyze_geographic_distribution(df)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # çœä»½åˆ†å¸ƒ
        if 'province_distribution' in geo_analysis:
            st.write("**çœä»½åˆ†å¸ƒ (Top 10)**")
            province_data = dict(list(geo_analysis['province_distribution'].items())[:10])
            fig_province = go.Figure(data=[
                go.Bar(
                    x=list(province_data.values()),
                    y=list(province_data.keys()),
                    orientation='h',
                    marker_color=analyzer.visualizer.color_palette[:len(province_data)]
                )
            ])
            fig_province.update_layout(
                title="ç”¨æˆ·çœä»½åˆ†å¸ƒ",
                xaxis_title="ç”¨æˆ·æ•°é‡",
                yaxis_title="çœä»½",
                height=400
            )
            st.plotly_chart(fig_province, use_container_width=True)
    
    with col2:
        # åŸå¸‚åˆ†å¸ƒ
        if 'city_distribution' in geo_analysis:
            st.write("**åŸå¸‚åˆ†å¸ƒ (Top 10)**")
            city_data = dict(list(geo_analysis['city_distribution'].items())[:10])
            fig_city = go.Figure(data=[
                go.Pie(
                    labels=list(city_data.keys()),
                    values=list(city_data.values()),
                    hole=0.3
                )
            ])
            fig_city.update_layout(title="ç”¨æˆ·åŸå¸‚åˆ†å¸ƒ")
            st.plotly_chart(fig_city, use_container_width=True)
    
    # åœ°ç†é›†ä¸­åº¦åˆ†æ
    if 'geographic_concentration' in geo_analysis:
        st.subheader("ğŸ“Š åœ°ç†é›†ä¸­åº¦åˆ†æ")
        
        concentration = geo_analysis['geographic_concentration']
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("åŸºå°¼ç³»æ•°", f"{concentration['gini_coefficient']:.3f}")
        with col2:
            st.metric("é›†ä¸­åº¦æ°´å¹³", concentration['concentration_level'].upper())
        with col3:
            if 'province_stats' in geo_analysis:
                st.metric("è¦†ç›–çœä»½æ•°", geo_analysis['province_stats']['total_provinces'])
        
        # é›†ä¸­åº¦è§£é‡Š
        concentration_level = concentration['concentration_level']
        if concentration_level == 'high':
            st.info("ğŸ¯ ç”¨æˆ·åœ°ç†åˆ†å¸ƒé«˜åº¦é›†ä¸­ï¼Œä¸»è¦é›†ä¸­åœ¨å°‘æ•°å‡ ä¸ªçœä»½")
        elif concentration_level == 'medium':
            st.info("ğŸ“ ç”¨æˆ·åœ°ç†åˆ†å¸ƒä¸­ç­‰é›†ä¸­ï¼Œåˆ†å¸ƒç›¸å¯¹å‡åŒ€")
        else:
            st.info("ğŸŒ ç”¨æˆ·åœ°ç†åˆ†å¸ƒè¾ƒä¸ºåˆ†æ•£ï¼Œè¦†ç›–é¢å¹¿")
    
    # è¯¦ç»†ç»Ÿè®¡è¡¨
    st.subheader("ğŸ“‹ è¯¦ç»†ç»Ÿè®¡è¡¨")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if 'province_distribution' in geo_analysis:
            st.write("**çœä»½ç»Ÿè®¡ (Top 10)**")
            province_items = list(geo_analysis['province_distribution'].items())[:10]
            province_df = pd.DataFrame(province_items, columns=['çœä»½', 'ç”¨æˆ·æ•°'])
            province_df['å æ¯”(%)'] = (province_df['ç”¨æˆ·æ•°'] / df.shape[0] * 100).round(2)
            st.dataframe(province_df, use_container_width=True)
    
    with col2:
        if 'city_distribution' in geo_analysis:
            st.write("**åŸå¸‚ç»Ÿè®¡ (Top 10)**")
            city_items = list(geo_analysis['city_distribution'].items())[:10]
            city_df = pd.DataFrame(city_items, columns=['åŸå¸‚', 'ç”¨æˆ·æ•°'])
            city_df['å æ¯”(%)'] = (city_df['ç”¨æˆ·æ•°'] / df.shape[0] * 100).round(2)
            st.dataframe(city_df, use_container_width=True)

def show_regional_behavior(df: pd.DataFrame, analyzer: GeoAnalyzer):
    """æ˜¾ç¤ºåŒºåŸŸè¡Œä¸ºå·®å¼‚"""
    st.subheader("ğŸ™ï¸ åŒºåŸŸè¡Œä¸ºå·®å¼‚åˆ†æ")
    
    # åˆ†æåŒºåŸŸè¡Œä¸º
    behavior_analysis = analyzer.analyze_regional_behavior(df)
    
    if 'æ³¨å†Œçœä»½' not in df.columns:
        st.warning("æ•°æ®ä¸­ç¼ºå°‘çœä»½ä¿¡æ¯ï¼Œæ— æ³•è¿›è¡ŒåŒºåŸŸè¡Œä¸ºåˆ†æ")
        return
    
    # é€‰æ‹©åˆ†ææŒ‡æ ‡
    available_metrics = [col for col in ['å¾®åšæ•°', 'å…³æ³¨æ•°', 'ç²‰ä¸æ•°'] if col in df.columns]
    
    if not available_metrics:
        st.warning("æ•°æ®ä¸­ç¼ºå°‘è¡Œä¸ºæŒ‡æ ‡ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        return
    
    selected_metric = st.selectbox("é€‰æ‹©åˆ†ææŒ‡æ ‡", available_metrics)
    
    # æŒ‰çœä»½ç»Ÿè®¡é€‰å®šæŒ‡æ ‡
    province_stats = df.groupby('æ³¨å†Œçœä»½')[selected_metric].agg([
        'count', 'mean', 'median', 'std'
    ]).round(2).reset_index()
    province_stats.columns = ['çœä»½', 'ç”¨æˆ·æ•°', 'å¹³å‡å€¼', 'ä¸­ä½æ•°', 'æ ‡å‡†å·®']
    province_stats = province_stats.sort_values('å¹³å‡å€¼', ascending=False)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # çœä»½è¡Œä¸ºæŒ‡æ ‡æ’è¡Œ
        st.write(f"**{selected_metric} - çœä»½æ’è¡Œ (Top 10)**")
        top_provinces = province_stats.head(10)
        
        fig_ranking = go.Figure(data=[
            go.Bar(
                x=top_provinces['å¹³å‡å€¼'],
                y=top_provinces['çœä»½'],
                orientation='h',
                marker_color=analyzer.visualizer.color_palette[:len(top_provinces)],
                text=top_provinces['å¹³å‡å€¼'].round(1),
                textposition='auto'
            )
        ])
        fig_ranking.update_layout(
            title=f"{selected_metric}çœä»½å¹³å‡å€¼æ’è¡Œ",
            xaxis_title=f"å¹³å‡{selected_metric}",
            yaxis_title="çœä»½",
            height=400
        )
        st.plotly_chart(fig_ranking, use_container_width=True)
    
    with col2:
        # çœä»½è¡Œä¸ºåˆ†å¸ƒç®±çº¿å›¾
        st.write(f"**{selected_metric} - åˆ†å¸ƒç®±çº¿å›¾**")
        
        # é€‰æ‹©ç”¨æˆ·æ•°è¾ƒå¤šçš„çœä»½è¿›è¡Œç®±çº¿å›¾åˆ†æ
        top_provinces_for_box = province_stats.head(8)['çœä»½'].tolist()
        df_filtered = df[df['æ³¨å†Œçœä»½'].isin(top_provinces_for_box)]
        
        fig_box = go.Figure()
        
        for province in top_provinces_for_box:
            province_data = df_filtered[df_filtered['æ³¨å†Œçœä»½'] == province][selected_metric]
            fig_box.add_trace(go.Box(
                y=province_data,
                name=province,
                boxpoints='outliers'
            ))
        
        fig_box.update_layout(
            title=f"{selected_metric}çœä»½åˆ†å¸ƒå¯¹æ¯”",
            yaxis_title=selected_metric,
            xaxis_title="çœä»½",
            height=400
        )
        st.plotly_chart(fig_box, use_container_width=True)
    
    # è¯¦ç»†ç»Ÿè®¡è¡¨
    st.subheader("ğŸ“Š çœä»½è¡Œä¸ºç»Ÿè®¡è¡¨")
    st.dataframe(province_stats, use_container_width=True)
    
    # è¡Œä¸ºå·®å¼‚æ´å¯Ÿ
    if len(province_stats) > 1:
        st.subheader("ğŸ’¡ åŒºåŸŸè¡Œä¸ºæ´å¯Ÿ")
        
        max_province = province_stats.iloc[0]
        min_province = province_stats.iloc[-1]
        
        insights = [
            f"ğŸ† {selected_metric}æœ€é«˜çš„çœä»½æ˜¯{max_province['çœä»½']}ï¼Œå¹³å‡å€¼ä¸º{max_province['å¹³å‡å€¼']:.1f}",
            f"ğŸ“‰ {selected_metric}æœ€ä½çš„çœä»½æ˜¯{min_province['çœä»½']}ï¼Œå¹³å‡å€¼ä¸º{min_province['å¹³å‡å€¼']:.1f}",
            f"ğŸ“ˆ æœ€é«˜ä¸æœ€ä½çœä»½çš„å·®å¼‚å€æ•°ä¸º{max_province['å¹³å‡å€¼'] / max_province['å¹³å‡å€¼'] if min_province['å¹³å‡å€¼'] > 0 else 'N/A':.1f}å€"
        ]
        
        for insight in insights:
            st.info(insight)

def show_geographic_heatmap(df: pd.DataFrame, analyzer: GeoAnalyzer):
    """æ˜¾ç¤ºåœ°ç†çƒ­åŠ›å›¾"""
    st.subheader("ğŸ”¥ åœ°ç†çƒ­åŠ›å›¾")
    
    # åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®
    heatmap_data = analyzer.create_geographic_heatmap_data(df)
    
    if heatmap_data.empty:
        st.warning("æ•°æ®ä¸­ç¼ºå°‘åŸå¸‚åæ ‡ä¿¡æ¯ï¼Œæ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾")
        st.info("ğŸ’¡ æç¤ºï¼šå½“å‰æ”¯æŒçš„åŸå¸‚åŒ…æ‹¬ï¼š" + "ã€".join(list(analyzer.city_coordinates.keys())[:10]) + "ç­‰")
        return
    
    # æ˜¾ç¤ºçƒ­åŠ›å›¾
    st.write("**ç”¨æˆ·åˆ†å¸ƒçƒ­åŠ›å›¾**")
    
    # åˆ›å»ºFoliumåœ°å›¾
    folium_map = analyzer.create_folium_map(heatmap_data)
    
    # åœ¨Streamlitä¸­æ˜¾ç¤ºåœ°å›¾
    map_data = st_folium(folium_map, width=700, height=500)
    
    # çƒ­åŠ›å›¾æ•°æ®ç»Ÿè®¡
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š çƒ­åŠ›å›¾ç»Ÿè®¡")
        st.metric("è¦†ç›–åŸå¸‚æ•°", len(heatmap_data))
        st.metric("æ€»ç”¨æˆ·æ•°", heatmap_data['user_count'].sum())
        st.metric("å¹³å‡æ¯åŸå¸‚ç”¨æˆ·æ•°", f"{heatmap_data['user_count'].mean():.1f}")
    
    with col2:
        st.subheader("ğŸ™ï¸ Top 5 åŸå¸‚")
        top_cities = heatmap_data.head(5)
        for idx, row in top_cities.iterrows():
            st.write(f"**{row['city']}**: {row['user_count']}äºº")
    
    # è¯¦ç»†åŸå¸‚æ•°æ®è¡¨
    st.subheader("ğŸ“‹ åŸå¸‚ç”¨æˆ·åˆ†å¸ƒè¯¦æƒ…")
    heatmap_display = heatmap_data.copy()
    heatmap_display['å æ¯”(%)'] = (heatmap_display['user_count'] / heatmap_display['user_count'].sum() * 100).round(2)
    heatmap_display = heatmap_display[['city', 'user_count', 'å æ¯”(%)']]
    heatmap_display.columns = ['åŸå¸‚', 'ç”¨æˆ·æ•°', 'å æ¯”(%)']
    st.dataframe(heatmap_display, use_container_width=True)

def show_city_rankings(df: pd.DataFrame, analyzer: GeoAnalyzer):
    """æ˜¾ç¤ºåŸå¸‚æ’è¡Œæ¦œ"""
    st.subheader("ğŸ† åŸå¸‚æ’è¡Œæ¦œ")
    
    if 'æ³¨å†ŒåŸå¸‚' not in df.columns:
        st.warning("æ•°æ®ä¸­ç¼ºå°‘åŸå¸‚ä¿¡æ¯")
        return
    
    # é€‰æ‹©æ’è¡ŒæŒ‡æ ‡
    ranking_options = {
        'ç”¨æˆ·æ•°é‡': 'count',
        'å¹³å‡å¾®åšæ•°': 'mean_posts',
        'å¹³å‡ç²‰ä¸æ•°': 'mean_followers',
        'å¹³å‡å…³æ³¨æ•°': 'mean_following'
    }
    
    selected_ranking = st.selectbox("é€‰æ‹©æ’è¡ŒæŒ‡æ ‡", list(ranking_options.keys()))
    
    # è®¡ç®—åŸå¸‚ç»Ÿè®¡æ•°æ®
    city_stats = df.groupby('æ³¨å†ŒåŸå¸‚').agg({
        'ç”¨æˆ·ID': 'count',
        'å¾®åšæ•°': 'mean' if 'å¾®åšæ•°' in df.columns else lambda x: 0,
        'ç²‰ä¸æ•°': 'mean' if 'ç²‰ä¸æ•°' in df.columns else lambda x: 0,
        'å…³æ³¨æ•°': 'mean' if 'å…³æ³¨æ•°' in df.columns else lambda x: 0
    }).round(2).reset_index()
    
    city_stats.columns = ['åŸå¸‚', 'ç”¨æˆ·æ•°é‡', 'å¹³å‡å¾®åšæ•°', 'å¹³å‡ç²‰ä¸æ•°', 'å¹³å‡å…³æ³¨æ•°']
    
    # æ ¹æ®é€‰æ‹©çš„æŒ‡æ ‡æ’åº
    sort_column = selected_ranking
    city_stats_sorted = city_stats.sort_values(sort_column, ascending=False)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # æ’è¡Œæ¦œå›¾è¡¨
        st.write(f"**{selected_ranking}æ’è¡Œæ¦œ (Top 15)**")
        top_cities = city_stats_sorted.head(15)
        
        fig_ranking = go.Figure(data=[
            go.Bar(
                x=top_cities[sort_column],
                y=top_cities['åŸå¸‚'],
                orientation='h',
                marker_color=analyzer.visualizer.color_palette[:len(top_cities)],
                text=top_cities[sort_column].round(1),
                textposition='auto'
            )
        ])
        
        fig_ranking.update_layout(
            title=f"åŸå¸‚{selected_ranking}æ’è¡Œæ¦œ",
            xaxis_title=selected_ranking,
            yaxis_title="åŸå¸‚",
            height=600
        )
        st.plotly_chart(fig_ranking, use_container_width=True)
    
    with col2:
        # Top 10 æ’è¡Œæ¦œ
        st.write(f"**Top 10 {selected_ranking}**")
        top_10 = city_stats_sorted.head(10)
        
        for idx, (_, row) in enumerate(top_10.iterrows(), 1):
            medal = "ğŸ¥‡" if idx == 1 else "ğŸ¥ˆ" if idx == 2 else "ğŸ¥‰" if idx == 3 else f"{idx}."
            st.write(f"{medal} **{row['åŸå¸‚']}**: {row[sort_column]:.1f}")
    
    # å®Œæ•´æ’è¡Œæ¦œè¡¨æ ¼
    st.subheader("ğŸ“Š å®Œæ•´åŸå¸‚æ’è¡Œæ¦œ")
    
    # æ·»åŠ æ’ååˆ—
    city_stats_sorted['æ’å'] = range(1, len(city_stats_sorted) + 1)
    city_stats_display = city_stats_sorted[['æ’å', 'åŸå¸‚', 'ç”¨æˆ·æ•°é‡', 'å¹³å‡å¾®åšæ•°', 'å¹³å‡ç²‰ä¸æ•°', 'å¹³å‡å…³æ³¨æ•°']]
    
    st.dataframe(city_stats_display, use_container_width=True)
    
    # æ’è¡Œæ¦œæ´å¯Ÿ
    st.subheader("ğŸ’¡ æ’è¡Œæ¦œæ´å¯Ÿ")
    
    top_city = city_stats_sorted.iloc[0]
    insights = [
        f"ğŸ† {selected_ranking}ç¬¬ä¸€åï¼š{top_city['åŸå¸‚']}ï¼Œæ•°å€¼ä¸º{top_city[sort_column]:.1f}",
        f"ğŸ“Š å…±æœ‰{len(city_stats_sorted)}ä¸ªåŸå¸‚å‚ä¸æ’å",
        f"ğŸ“ˆ å‰ä¸‰ååŸå¸‚å æ€»ç”¨æˆ·æ•°çš„{city_stats_sorted.head(3)['ç”¨æˆ·æ•°é‡'].sum() / city_stats_sorted['ç”¨æˆ·æ•°é‡'].sum() * 100:.1f}%"
    ]
    
    for insight in insights:
        st.info(insight)

def show_geographic_insights(df: pd.DataFrame, analyzer: GeoAnalyzer):
    """æ˜¾ç¤ºåœ°ç†æ´å¯ŸæŠ¥å‘Š"""
    st.subheader("ğŸ“‹ åœ°ç†æ´å¯ŸæŠ¥å‘Š")
    
    # è·å–æ‰€æœ‰åˆ†æç»“æœ
    geo_analysis = analyzer.analyze_geographic_distribution(df)
    behavior_analysis = analyzer.analyze_regional_behavior(df)
    heatmap_data = analyzer.create_geographic_heatmap_data(df)
    
    # å…³é”®æŒ‡æ ‡æ¦‚è§ˆ
    st.subheader("ğŸ“Š å…³é”®æŒ‡æ ‡æ¦‚è§ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if 'province_stats' in geo_analysis:
            st.metric("è¦†ç›–çœä»½", geo_analysis['province_stats']['total_provinces'])
    
    with col2:
        if 'city_stats' in geo_analysis:
            st.metric("è¦†ç›–åŸå¸‚", geo_analysis['city_stats']['total_cities'])
    
    with col3:
        if 'province_stats' in geo_analysis:
            st.metric("ä¸»è¦çœä»½å æ¯”", f"{geo_analysis['province_stats']['top_province_ratio']:.1f}%")
    
    with col4:
        if not heatmap_data.empty:
            st.metric("çƒ­åŠ›å›¾è¦†ç›–åŸå¸‚", len(heatmap_data))
    
    # åœ°ç†åˆ†å¸ƒç‰¹å¾
    st.subheader("ğŸ—ºï¸ åœ°ç†åˆ†å¸ƒç‰¹å¾")
    
    distribution_insights = []
    
    if 'province_stats' in geo_analysis:
        top_province = geo_analysis['province_stats']['top_province']
        top_ratio = geo_analysis['province_stats']['top_province_ratio']
        distribution_insights.append(f"ğŸ¯ ç”¨æˆ·ä¸»è¦é›†ä¸­åœ¨{top_province}ï¼Œå æ¯”{top_ratio:.1f}%")
    
    if 'geographic_concentration' in geo_analysis:
        concentration = geo_analysis['geographic_concentration']
        gini = concentration['gini_coefficient']
        level = concentration['concentration_level']
        distribution_insights.append(f"ğŸ“ˆ åœ°ç†é›†ä¸­åº¦åŸºå°¼ç³»æ•°ä¸º{gini:.3f}ï¼Œå±äº{level}é›†ä¸­åº¦")
    
    if 'city_stats' in geo_analysis:
        top_city = geo_analysis['city_stats']['top_city']
        city_ratio = geo_analysis['city_stats']['top_city_ratio']
        distribution_insights.append(f"ğŸ™ï¸ ç”¨æˆ·æœ€å¤šçš„åŸå¸‚æ˜¯{top_city}ï¼Œå æ¯”{city_ratio:.1f}%")
    
    for insight in distribution_insights:
        st.info(insight)
    
    # åŒºåŸŸè¡Œä¸ºç‰¹å¾
    if behavior_analysis:
        st.subheader("ğŸƒ åŒºåŸŸè¡Œä¸ºç‰¹å¾")
        
        behavior_insights = []
        
        if 'most_active_province' in behavior_analysis:
            most_active = behavior_analysis['most_active_province']
            behavior_insights.append(f"âš¡ æœ€æ´»è·ƒçš„çœä»½ï¼š{most_active}ï¼ˆå¹³å‡å¾®åšæ•°æœ€é«˜ï¼‰")
        
        if 'most_influential_province' in behavior_analysis:
            most_influential = behavior_analysis['most_influential_province']
            behavior_insights.append(f"ğŸŒŸ æœ€å…·å½±å“åŠ›çš„çœä»½ï¼š{most_influential}ï¼ˆå¹³å‡ç²‰ä¸æ•°æœ€é«˜ï¼‰")
        
        for insight in behavior_insights:
            st.success(insight)
    
    # çƒ­åŠ›å›¾åˆ†æ
    if not heatmap_data.empty:
        st.subheader("ğŸ”¥ çƒ­åŠ›å›¾åˆ†æ")
        
        top_3_cities = heatmap_data.head(3)
        heatmap_insights = [
            f"ğŸ† ç”¨æˆ·å¯†åº¦æœ€é«˜çš„ä¸‰ä¸ªåŸå¸‚ï¼š{', '.join(top_3_cities['city'].tolist())}",
            f"ğŸ“Š çƒ­åŠ›å›¾è¦†ç›–{len(heatmap_data)}ä¸ªä¸»è¦åŸå¸‚",
            f"ğŸ¯ å‰ä¸‰ååŸå¸‚ç”¨æˆ·æ•°å çƒ­åŠ›å›¾æ€»æ•°çš„{top_3_cities['user_count'].sum() / heatmap_data['user_count'].sum() * 100:.1f}%"
        ]
        
        for insight in heatmap_insights:
            st.info(insight)
    
    # ç»¼åˆå»ºè®®
    st.subheader("ğŸ’¡ ç­–ç•¥å»ºè®®")
    
    recommendations = [
        "ğŸ¯ **é‡ç‚¹åŒºåŸŸç­–ç•¥**ï¼šé’ˆå¯¹ç”¨æˆ·é›†ä¸­çš„ä¸»è¦çœä»½å’ŒåŸå¸‚åˆ¶å®šä¸“é—¨çš„è¿è¥ç­–ç•¥",
        "ğŸŒ **åŒºåŸŸæ‰©å¼ ç­–ç•¥**ï¼šåœ¨ç”¨æˆ·è¾ƒå°‘ä½†æ½œåŠ›è¾ƒå¤§çš„åœ°åŒºåŠ å¼ºæ¨å¹¿å’Œè¿è¥",
        "ğŸ“Š **å·®å¼‚åŒ–è¿è¥**ï¼šæ ¹æ®ä¸åŒåœ°åŒºç”¨æˆ·çš„è¡Œä¸ºç‰¹å¾åˆ¶å®šä¸ªæ€§åŒ–å†…å®¹ç­–ç•¥",
        "ğŸ”¥ **çƒ­ç‚¹åŸå¸‚æ·±è€•**ï¼šåœ¨ç”¨æˆ·å¯†åº¦é«˜çš„åŸå¸‚åŠ å¼ºæœ¬åœ°åŒ–æœåŠ¡å’Œæ´»åŠ¨",
        "ğŸ“ˆ **æ•°æ®é©±åŠ¨å†³ç­–**ï¼šæŒç»­ç›‘æ§åœ°ç†åˆ†å¸ƒå˜åŒ–ï¼ŒåŠæ—¶è°ƒæ•´åŒºåŸŸç­–ç•¥"
    ]
    
    for recommendation in recommendations:
        st.markdown(recommendation)
    
    # æ•°æ®è´¨é‡è¯´æ˜
    st.subheader("â„¹ï¸ æ•°æ®è¯´æ˜")
    
    data_notes = [
        f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´ï¼šåŸºäºå½“å‰åŠ è½½çš„{len(df)}æ¡ç”¨æˆ·æ•°æ®",
        "ğŸ—ºï¸ åœ°ç†åæ ‡ï¼šçƒ­åŠ›å›¾åŸºäºé¢„è®¾çš„ä¸»è¦åŸå¸‚åæ ‡ï¼Œå¯èƒ½ä¸åŒ…å«æ‰€æœ‰åŸå¸‚",
        "ğŸ“Š ç»Ÿè®¡æ–¹æ³•ï¼šé‡‡ç”¨æè¿°æ€§ç»Ÿè®¡å’ŒåŸºå°¼ç³»æ•°ç­‰æ–¹æ³•åˆ†æåœ°ç†é›†ä¸­åº¦",
        "âš ï¸ æ•°æ®é™åˆ¶ï¼šåˆ†æç»“æœåŸºäºæ ·æœ¬æ•°æ®ï¼Œå®é™…åº”ç”¨æ—¶éœ€è€ƒè™‘æ•°æ®å®Œæ•´æ€§"
    ]
    
    for note in data_notes:
        st.caption(note)

if __name__ == "__main__":
    main()