import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import networkx as nx
import sys
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from utils.visualizer import UserBehaviorVisualizer, create_dashboard_metrics, display_metrics_cards
from utils.cache_manager import cache_data
from config.settings import get_config

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ç¤¾äº¤ç½‘ç»œåˆ†æ",
    page_icon="ğŸŒ",
    layout="wide"
)

class SocialNetworkAnalyzer:
    """ç¤¾äº¤ç½‘ç»œåˆ†æå™¨"""
    
    def __init__(self):
        self.visualizer = UserBehaviorVisualizer()
        self.viz_config = get_config('viz')
    
    @cache_data(ttl=1800)
    def analyze_user_interactions(self, df: pd.DataFrame) -> dict:
        """åˆ†æç”¨æˆ·äº’åŠ¨æ¨¡å¼"""
        analysis = {}
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['ç”¨æˆ·ID', 'æ˜µç§°']
        missing_fields = [field for field in required_fields if field not in df.columns]
        
        if missing_fields:
            analysis['error'] = f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}"
            return analysis
        
        # ç”¨æˆ·åŸºç¡€ç»Ÿè®¡
        unique_users = df['ç”¨æˆ·ID'].nunique()
        total_posts = len(df)
        
        analysis['basic_stats'] = {
            'unique_users': unique_users,
            'total_posts': total_posts,
            'avg_posts_per_user': total_posts / unique_users if unique_users > 0 else 0
        }
        
        # ç”¨æˆ·æ´»è·ƒåº¦åˆ†æ
        user_activity = df.groupby('ç”¨æˆ·ID').agg({
            'æ˜µç§°': 'first',
            'å¾®åšæ•°': 'first',
            'å…³æ³¨æ•°': 'first',
            'ç²‰ä¸æ•°': 'first'
        }).reset_index()
        
        # è®¡ç®—äº’åŠ¨æŒ‡æ ‡
        if 'å¾®åšæ•°' in df.columns:
            user_activity['å‘å¸ƒæ´»è·ƒåº¦'] = user_activity['å¾®åšæ•°']
        
        if 'å…³æ³¨æ•°' in df.columns and 'ç²‰ä¸æ•°' in df.columns:
            user_activity['å…³æ³¨ç²‰ä¸æ¯”'] = user_activity['å…³æ³¨æ•°'] / (user_activity['ç²‰ä¸æ•°'] + 1)
            user_activity['å½±å“åŠ›æŒ‡æ•°'] = user_activity['ç²‰ä¸æ•°'] / (user_activity['å…³æ³¨æ•°'] + 1)
        
        analysis['user_activity'] = user_activity
        
        # æ´»è·ƒåº¦åˆ†å±‚
        if 'å¾®åšæ•°' in df.columns:
            weibo_counts = user_activity['å¾®åšæ•°'].fillna(0)
            
            # å®šä¹‰æ´»è·ƒåº¦ç­‰çº§
            activity_levels = {
                'è¶…çº§æ´»è·ƒ': weibo_counts >= weibo_counts.quantile(0.9),
                'é«˜åº¦æ´»è·ƒ': (weibo_counts >= weibo_counts.quantile(0.7)) & (weibo_counts < weibo_counts.quantile(0.9)),
                'ä¸­åº¦æ´»è·ƒ': (weibo_counts >= weibo_counts.quantile(0.3)) & (weibo_counts < weibo_counts.quantile(0.7)),
                'ä½åº¦æ´»è·ƒ': weibo_counts < weibo_counts.quantile(0.3)
            }
            
            activity_distribution = {}
            for level, condition in activity_levels.items():
                activity_distribution[level] = condition.sum()
            
            analysis['activity_distribution'] = activity_distribution
        
        # å½±å“åŠ›åˆ†æ
        if 'ç²‰ä¸æ•°' in df.columns:
            fans_counts = user_activity['ç²‰ä¸æ•°'].fillna(0)
            
            influence_levels = {
                'KOLçº§åˆ«': fans_counts >= fans_counts.quantile(0.95),
                'é«˜å½±å“åŠ›': (fans_counts >= fans_counts.quantile(0.8)) & (fans_counts < fans_counts.quantile(0.95)),
                'ä¸­ç­‰å½±å“åŠ›': (fans_counts >= fans_counts.quantile(0.5)) & (fans_counts < fans_counts.quantile(0.8)),
                'æ™®é€šç”¨æˆ·': fans_counts < fans_counts.quantile(0.5)
            }
            
            influence_distribution = {}
            for level, condition in influence_levels.items():
                influence_distribution[level] = condition.sum()
            
            analysis['influence_distribution'] = influence_distribution
        
        return analysis
    
    @cache_data(ttl=1800)
    def analyze_mention_network(self, df: pd.DataFrame, text_column: str = 'å¾®åšæ–‡æœ¬') -> dict:
        """åˆ†æ@æåŠç½‘ç»œ"""
        analysis = {}
        
        if text_column not in df.columns:
            analysis['error'] = f"ç¼ºå°‘æ–‡æœ¬å­—æ®µ: {text_column}"
            return analysis
        
        # æå–@æåŠ
        import re
        mention_pattern = re.compile(r'@([\w\u4e00-\u9fff]+)')
        
        mentions_data = []
        
        for idx, row in df.iterrows():
            if pd.notna(row[text_column]):
                text = str(row[text_column])
                mentions = mention_pattern.findall(text)
                
                for mentioned_user in mentions:
                    mentions_data.append({
                        'from_user': row.get('æ˜µç§°', row.get('ç”¨æˆ·ID', f'ç”¨æˆ·{idx}')),
                        'to_user': mentioned_user,
                        'from_user_id': row.get('ç”¨æˆ·ID', idx),
                        'post_content': text[:100] + '...' if len(text) > 100 else text
                    })
        
        if not mentions_data:
            analysis['mentions_count'] = 0
            analysis['network_stats'] = {'nodes': 0, 'edges': 0, 'density': 0}
            return analysis
        
        mentions_df = pd.DataFrame(mentions_data)
        
        # æåŠç»Ÿè®¡
        analysis['mentions_count'] = len(mentions_df)
        analysis['unique_mentioners'] = mentions_df['from_user'].nunique()
        analysis['unique_mentioned'] = mentions_df['to_user'].nunique()
        
        # æœ€å¸¸è¢«æåŠçš„ç”¨æˆ·
        most_mentioned = mentions_df['to_user'].value_counts().head(10)
        analysis['most_mentioned'] = most_mentioned.to_dict()
        
        # æœ€æ´»è·ƒçš„æåŠè€…
        most_mentioners = mentions_df['from_user'].value_counts().head(10)
        analysis['most_mentioners'] = most_mentioners.to_dict()
        
        # æ„å»ºç½‘ç»œå›¾
        try:
            G = nx.from_pandas_edgelist(
                mentions_df, 
                source='from_user', 
                target='to_user', 
                create_using=nx.DiGraph()
            )
            
            # ç½‘ç»œç»Ÿè®¡
            analysis['network_stats'] = {
                'nodes': G.number_of_nodes(),
                'edges': G.number_of_edges(),
                'density': nx.density(G),
                'is_connected': nx.is_weakly_connected(G)
            }
            
            # ä¸­å¿ƒæ€§åˆ†æ
            if G.number_of_nodes() > 0:
                # åº¦ä¸­å¿ƒæ€§
                in_degree_centrality = nx.in_degree_centrality(G)
                out_degree_centrality = nx.out_degree_centrality(G)
                
                # è·å–å‰10ä¸ªæœ€æœ‰å½±å“åŠ›çš„èŠ‚ç‚¹
                top_in_degree = sorted(in_degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]
                top_out_degree = sorted(out_degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]
                
                analysis['centrality'] = {
                    'top_in_degree': dict(top_in_degree),
                    'top_out_degree': dict(top_out_degree)
                }
                
                # ä¿å­˜ç½‘ç»œå›¾æ•°æ®ç”¨äºå¯è§†åŒ–
                pos = nx.spring_layout(G, k=1, iterations=50)
                
                edge_trace = []
                node_trace = []
                
                # è¾¹æ•°æ®
                for edge in G.edges():
                    x0, y0 = pos[edge[0]]
                    x1, y1 = pos[edge[1]]
                    edge_trace.extend([x0, x1, None])
                    edge_trace.extend([y0, y1, None])
                
                # èŠ‚ç‚¹æ•°æ®
                node_x = []
                node_y = []
                node_text = []
                node_size = []
                
                for node in G.nodes():
                    x, y = pos[node]
                    node_x.append(x)
                    node_y.append(y)
                    
                    # èŠ‚ç‚¹å¤§å°åŸºäºå…¥åº¦
                    in_degree = G.in_degree(node)
                    node_size.append(max(10, in_degree * 5))
                    
                    # èŠ‚ç‚¹æ ‡ç­¾
                    node_text.append(f"{node}<br>è¢«æåŠ: {in_degree}æ¬¡")
                
                analysis['network_viz'] = {
                    'edge_x': edge_trace[::3],
                    'edge_y': edge_trace[1::3],
                    'node_x': node_x,
                    'node_y': node_y,
                    'node_text': node_text,
                    'node_size': node_size
                }
        
        except Exception as e:
            analysis['network_error'] = str(e)
        
        return analysis
    
    @cache_data(ttl=1800)
    def analyze_follower_patterns(self, df: pd.DataFrame) -> dict:
        """åˆ†æå…³æ³¨è€…æ¨¡å¼"""
        analysis = {}
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if 'å…³æ³¨æ•°' not in df.columns or 'ç²‰ä¸æ•°' not in df.columns:
            analysis['error'] = "ç¼ºå°‘å…³æ³¨æ•°æˆ–ç²‰ä¸æ•°å­—æ®µ"
            return analysis
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        valid_data = df[(df['å…³æ³¨æ•°'].notna()) & (df['ç²‰ä¸æ•°'].notna())].copy()
        
        if valid_data.empty:
            analysis['error'] = "æ²¡æœ‰æœ‰æ•ˆçš„å…³æ³¨/ç²‰ä¸æ•°æ®"
            return analysis
        
        # åŸºç¡€ç»Ÿè®¡
        analysis['basic_stats'] = {
            'total_users': len(valid_data),
            'avg_following': valid_data['å…³æ³¨æ•°'].mean(),
            'avg_followers': valid_data['ç²‰ä¸æ•°'].mean(),
            'median_following': valid_data['å…³æ³¨æ•°'].median(),
            'median_followers': valid_data['ç²‰ä¸æ•°'].median(),
            'max_following': valid_data['å…³æ³¨æ•°'].max(),
            'max_followers': valid_data['ç²‰ä¸æ•°'].max()
        }
        
        # å…³æ³¨ç²‰ä¸æ¯”åˆ†æ
        valid_data['å…³æ³¨ç²‰ä¸æ¯”'] = valid_data['å…³æ³¨æ•°'] / (valid_data['ç²‰ä¸æ•°'] + 1)
        valid_data['å½±å“åŠ›æŒ‡æ•°'] = valid_data['ç²‰ä¸æ•°'] / (valid_data['å…³æ³¨æ•°'] + 1)
        
        # ç”¨æˆ·ç±»å‹åˆ†ç±»
        user_types = {
            'æ„è§é¢†è¢–': (valid_data['ç²‰ä¸æ•°'] > valid_data['ç²‰ä¸æ•°'].quantile(0.9)) & 
                      (valid_data['å…³æ³¨ç²‰ä¸æ¯”'] < 1),
            'æ´»è·ƒç”¨æˆ·': (valid_data['å…³æ³¨æ•°'] > valid_data['å…³æ³¨æ•°'].quantile(0.7)) & 
                      (valid_data['ç²‰ä¸æ•°'] > valid_data['ç²‰ä¸æ•°'].quantile(0.3)),
            'æ½œæ°´ç”¨æˆ·': (valid_data['å…³æ³¨æ•°'] < valid_data['å…³æ³¨æ•°'].quantile(0.3)) & 
                      (valid_data['ç²‰ä¸æ•°'] < valid_data['ç²‰ä¸æ•°'].quantile(0.3)),
            'å…³æ³¨ç‹‚': valid_data['å…³æ³¨æ•°'] > valid_data['å…³æ³¨æ•°'].quantile(0.9),
            'æ™®é€šç”¨æˆ·': True  # é»˜è®¤ç±»åˆ«
        }
        
        user_type_distribution = {}
        for user_type, condition in user_types.items():
            if user_type == 'æ™®é€šç”¨æˆ·':
                # æ™®é€šç”¨æˆ·æ˜¯å…¶ä»–ç±»å‹ä¹‹å¤–çš„ç”¨æˆ·
                other_conditions = [user_types[t] for t in user_types.keys() if t != 'æ™®é€šç”¨æˆ·']
                combined_condition = pd.Series([False] * len(valid_data))
                for cond in other_conditions:
                    combined_condition = combined_condition | cond
                user_type_distribution[user_type] = (~combined_condition).sum()
            else:
                user_type_distribution[user_type] = condition.sum()
        
        analysis['user_type_distribution'] = user_type_distribution
        
        # å…³æ³¨ç²‰ä¸æ¯”åˆ†å¸ƒ
        ratio_bins = [0, 0.1, 0.5, 1, 2, 5, float('inf')]
        ratio_labels = ['è¶…é«˜å½±å“åŠ›', 'é«˜å½±å“åŠ›', 'å¹³è¡¡å‹', 'å…³æ³¨å‹', 'é«˜å…³æ³¨å‹', 'å…³æ³¨ç‹‚']
        
        ratio_distribution = pd.cut(
            valid_data['å…³æ³¨ç²‰ä¸æ¯”'], 
            bins=ratio_bins, 
            labels=ratio_labels, 
            right=False
        ).value_counts()
        
        analysis['ratio_distribution'] = ratio_distribution.to_dict()
        
        # å½±å“åŠ›åˆ†å±‚
        influence_levels = {
            'è¶…çº§å½±å“è€…': valid_data['ç²‰ä¸æ•°'] >= valid_data['ç²‰ä¸æ•°'].quantile(0.95),
            'é«˜å½±å“è€…': (valid_data['ç²‰ä¸æ•°'] >= valid_data['ç²‰ä¸æ•°'].quantile(0.8)) & 
                       (valid_data['ç²‰ä¸æ•°'] < valid_data['ç²‰ä¸æ•°'].quantile(0.95)),
            'ä¸­ç­‰å½±å“è€…': (valid_data['ç²‰ä¸æ•°'] >= valid_data['ç²‰ä¸æ•°'].quantile(0.5)) & 
                        (valid_data['ç²‰ä¸æ•°'] < valid_data['ç²‰ä¸æ•°'].quantile(0.8)),
            'æ™®é€šç”¨æˆ·': valid_data['ç²‰ä¸æ•°'] < valid_data['ç²‰ä¸æ•°'].quantile(0.5)
        }
        
        influence_distribution = {}
        for level, condition in influence_levels.items():
            influence_distribution[level] = condition.sum()
        
        analysis['influence_distribution'] = influence_distribution
        
        # ç›¸å…³æ€§åˆ†æ
        correlation = valid_data[['å…³æ³¨æ•°', 'ç²‰ä¸æ•°']].corr().iloc[0, 1]
        analysis['following_followers_correlation'] = correlation
        
        # å¼‚å¸¸å€¼æ£€æµ‹
        following_q99 = valid_data['å…³æ³¨æ•°'].quantile(0.99)
        followers_q99 = valid_data['ç²‰ä¸æ•°'].quantile(0.99)
        
        outliers = valid_data[
            (valid_data['å…³æ³¨æ•°'] > following_q99) | 
            (valid_data['ç²‰ä¸æ•°'] > followers_q99)
        ]
        
        analysis['outliers'] = {
            'count': len(outliers),
            'high_following': (valid_data['å…³æ³¨æ•°'] > following_q99).sum(),
            'high_followers': (valid_data['ç²‰ä¸æ•°'] > followers_q99).sum()
        }
        
        return analysis
    
    @cache_data(ttl=1800)
    def analyze_interaction_intensity(self, df: pd.DataFrame) -> dict:
        """åˆ†æäº’åŠ¨å¼ºåº¦"""
        analysis = {}
        
        # æ£€æŸ¥æ–‡æœ¬å­—æ®µ
        text_columns = [col for col in df.columns if 'å†…å®¹' in col]
        if not text_columns:
            analysis['error'] = "æ²¡æœ‰æ‰¾åˆ°å†…å®¹å­—æ®µ"
            return analysis
        
        text_column = text_columns[0]
        
        # æå–äº’åŠ¨å…ƒç´ 
        import re
        
        mention_pattern = re.compile(r'@[\w\u4e00-\u9fff]+')
        hashtag_pattern = re.compile(r'#[^#]+#')
        url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')
        
        interaction_data = []
        
        for idx, row in df.iterrows():
            if pd.notna(row[text_column]):
                text = str(row[text_column])
                
                mentions = len(mention_pattern.findall(text))
                hashtags = len(hashtag_pattern.findall(text))
                urls = len(url_pattern.findall(text))
                
                # è®¡ç®—äº’åŠ¨å¼ºåº¦å¾—åˆ†
                interaction_score = mentions * 3 + hashtags * 2 + urls * 1
                
                interaction_data.append({
                    'user_id': row.get('ç”¨æˆ·ID', idx),
                    'user_name': row.get('æ˜µç§°', f'ç”¨æˆ·{idx}'),
                    'mentions': mentions,
                    'hashtags': hashtags,
                    'urls': urls,
                    'interaction_score': interaction_score,
                    'text_length': len(text)
                })
        
        if not interaction_data:
            analysis['error'] = "æ²¡æœ‰æœ‰æ•ˆçš„äº’åŠ¨æ•°æ®"
            return analysis
        
        interaction_df = pd.DataFrame(interaction_data)
        
        # åŸºç¡€ç»Ÿè®¡
        analysis['basic_stats'] = {
            'total_posts': len(interaction_df),
            'avg_mentions': interaction_df['mentions'].mean(),
            'avg_hashtags': interaction_df['hashtags'].mean(),
            'avg_urls': interaction_df['urls'].mean(),
            'avg_interaction_score': interaction_df['interaction_score'].mean()
        }
        
        # äº’åŠ¨å¼ºåº¦åˆ†å¸ƒ
        score_bins = [0, 1, 3, 6, 10, float('inf')]
        score_labels = ['æ— äº’åŠ¨', 'ä½äº’åŠ¨', 'ä¸­ç­‰äº’åŠ¨', 'é«˜äº’åŠ¨', 'è¶…é«˜äº’åŠ¨']
        
        intensity_distribution = pd.cut(
            interaction_df['interaction_score'],
            bins=score_bins,
            labels=score_labels,
            right=False
        ).value_counts()
        
        analysis['intensity_distribution'] = intensity_distribution.to_dict()
        
        # ç”¨æˆ·äº’åŠ¨æ’è¡Œ
        user_interaction = interaction_df.groupby(['user_id', 'user_name']).agg({
            'mentions': 'sum',
            'hashtags': 'sum',
            'urls': 'sum',
            'interaction_score': 'sum'
        }).reset_index()
        
        # æœ€æ´»è·ƒäº’åŠ¨ç”¨æˆ·
        top_interactive_users = user_interaction.nlargest(10, 'interaction_score')
        analysis['top_interactive_users'] = top_interactive_users.to_dict('records')
        
        # äº’åŠ¨ç±»å‹åå¥½
        total_interactions = {
            'mentions': interaction_df['mentions'].sum(),
            'hashtags': interaction_df['hashtags'].sum(),
            'urls': interaction_df['urls'].sum()
        }
        
        total_count = sum(total_interactions.values())
        if total_count > 0:
            interaction_preferences = {
                k: v / total_count * 100 for k, v in total_interactions.items()
            }
            analysis['interaction_preferences'] = interaction_preferences
        
        # äº’åŠ¨ä¸æ–‡æœ¬é•¿åº¦çš„å…³ç³»
        if len(interaction_df) > 1:
            length_interaction_corr = interaction_df[['text_length', 'interaction_score']].corr().iloc[0, 1]
            analysis['length_interaction_correlation'] = length_interaction_corr
        
        return analysis

def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸŒ ç¤¾äº¤ç½‘ç»œåˆ†æ")
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦å·²åŠ è½½
    if 'data_loaded' not in st.session_state or not st.session_state.data_loaded:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¸»é¡µåŠ è½½æ•°æ®")
        st.stop()
    
    # è·å–æ•°æ®
    df = st.session_state.get('filtered_data', st.session_state.current_data)
    
    # ç¡®ä¿æ•°æ®ä¸ä¸ºNone
    if df is None:
        st.error("âŒ æ•°æ®è·å–å¤±è´¥ï¼Œè¯·è¿”å›ä¸»é¡µé‡æ–°åŠ è½½æ•°æ®")
        st.stop()
    
    analyzer = SocialNetworkAnalyzer()
    
    # ä¾§è¾¹æ æ§åˆ¶
    st.sidebar.subheader("ğŸŒ åˆ†æé€‰é¡¹")
    
    analysis_type = st.sidebar.selectbox(
        "é€‰æ‹©åˆ†æç±»å‹",
        ["ç”¨æˆ·äº’åŠ¨åˆ†æ", "@æåŠç½‘ç»œ", "å…³æ³¨è€…æ¨¡å¼", "äº’åŠ¨å¼ºåº¦åˆ†æ", "ç¤¾äº¤ç½‘ç»œæŠ¥å‘Š"]
    )
    
    # æ•°æ®æ¦‚è§ˆ
    st.subheader("ğŸ“ˆ æ•°æ®æ¦‚è§ˆ")
    metrics = create_dashboard_metrics(df)
    display_metrics_cards(metrics)
    
    # æ ¹æ®é€‰æ‹©çš„åˆ†æç±»å‹æ˜¾ç¤ºå†…å®¹
    if analysis_type == "ç”¨æˆ·äº’åŠ¨åˆ†æ":
        show_user_interaction_analysis(df, analyzer)
    elif analysis_type == "@æåŠç½‘ç»œ":
        show_mention_network_analysis(df, analyzer)
    elif analysis_type == "å…³æ³¨è€…æ¨¡å¼":
        show_follower_pattern_analysis(df, analyzer)
    elif analysis_type == "äº’åŠ¨å¼ºåº¦åˆ†æ":
        show_interaction_intensity_analysis(df, analyzer)
    elif analysis_type == "ç¤¾äº¤ç½‘ç»œæŠ¥å‘Š":
        show_social_network_report(df, analyzer)

def show_user_interaction_analysis(df: pd.DataFrame, analyzer: SocialNetworkAnalyzer):
    """æ˜¾ç¤ºç”¨æˆ·äº’åŠ¨åˆ†æ"""
    st.subheader("ğŸ‘¥ ç”¨æˆ·äº’åŠ¨åˆ†æ")
    
    # åˆ†æç”¨æˆ·äº’åŠ¨
    interaction_analysis = analyzer.analyze_user_interactions(df)
    
    if 'error' in interaction_analysis:
        st.error(f"âŒ {interaction_analysis['error']}")
        return
    
    # åŸºç¡€ç»Ÿè®¡
    if 'basic_stats' in interaction_analysis:
        st.subheader("ğŸ“Š åŸºç¡€ç»Ÿè®¡")
        
        stats = interaction_analysis['basic_stats']
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç”¨æˆ·æ€»æ•°", stats['unique_users'])
        with col2:
            st.metric("å†…å®¹æ€»æ•°", stats['total_posts'])
        with col3:
            st.metric("äººå‡å‘å¸ƒ", f"{stats['avg_posts_per_user']:.1f}æ¡")
    
    # æ´»è·ƒåº¦åˆ†å¸ƒ
    if 'activity_distribution' in interaction_analysis:
        st.subheader("ğŸ“ˆ ç”¨æˆ·æ´»è·ƒåº¦åˆ†å¸ƒ")
        
        activity_dist = interaction_analysis['activity_distribution']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # æ´»è·ƒåº¦æŸ±çŠ¶å›¾
            fig_activity = go.Figure(data=[
                go.Bar(
                    x=list(activity_dist.keys()),
                    y=list(activity_dist.values()),
                    marker_color=analyzer.visualizer.color_palette[0],
                    text=list(activity_dist.values()),
                    textposition='auto'
                )
            ])
            fig_activity.update_layout(
                title="ç”¨æˆ·æ´»è·ƒåº¦åˆ†å¸ƒ",
                xaxis_title="æ´»è·ƒåº¦ç­‰çº§",
                yaxis_title="ç”¨æˆ·æ•°é‡"
            )
            st.plotly_chart(fig_activity, use_container_width=True)
        
        with col2:
            # æ´»è·ƒåº¦é¥¼å›¾
            fig_activity_pie = go.Figure(data=[
                go.Pie(
                    labels=list(activity_dist.keys()),
                    values=list(activity_dist.values()),
                    hole=0.3
                )
            ])
            fig_activity_pie.update_layout(title="æ´»è·ƒåº¦å æ¯”")
            st.plotly_chart(fig_activity_pie, use_container_width=True)
    
    # å½±å“åŠ›åˆ†å¸ƒ
    if 'influence_distribution' in interaction_analysis:
        st.subheader("â­ ç”¨æˆ·å½±å“åŠ›åˆ†å¸ƒ")
        
        influence_dist = interaction_analysis['influence_distribution']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å½±å“åŠ›æŸ±çŠ¶å›¾
            fig_influence = go.Figure(data=[
                go.Bar(
                    x=list(influence_dist.keys()),
                    y=list(influence_dist.values()),
                    marker_color=analyzer.visualizer.color_palette[1],
                    text=list(influence_dist.values()),
                    textposition='auto'
                )
            ])
            fig_influence.update_layout(
                title="ç”¨æˆ·å½±å“åŠ›åˆ†å¸ƒ",
                xaxis_title="å½±å“åŠ›ç­‰çº§",
                yaxis_title="ç”¨æˆ·æ•°é‡"
            )
            st.plotly_chart(fig_influence, use_container_width=True)
        
        with col2:
            # å½±å“åŠ›é¥¼å›¾
            fig_influence_pie = go.Figure(data=[
                go.Pie(
                    labels=list(influence_dist.keys()),
                    values=list(influence_dist.values()),
                    hole=0.3
                )
            ])
            fig_influence_pie.update_layout(title="å½±å“åŠ›å æ¯”")
            st.plotly_chart(fig_influence_pie, use_container_width=True)
    
    # ç”¨æˆ·æ´»åŠ¨è¯¦æƒ…
    if 'user_activity' in interaction_analysis:
        st.subheader("ğŸ“‹ ç”¨æˆ·æ´»åŠ¨è¯¦æƒ…")
        
        user_activity = interaction_analysis['user_activity']
        
        # æ˜¾ç¤ºå‰20ä¸ªæœ€æ´»è·ƒç”¨æˆ·
        if 'å¾®åšæ•°' in user_activity.columns:
            top_active_users = user_activity.nlargest(20, 'å¾®åšæ•°')
            
            st.write("**æœ€æ´»è·ƒç”¨æˆ·(å‰20)**")
            display_columns = ['æ˜µç§°', 'å¾®åšæ•°', 'å…³æ³¨æ•°', 'ç²‰ä¸æ•°']
            available_columns = [col for col in display_columns if col in top_active_users.columns]
            
            if available_columns:
                st.dataframe(
                    top_active_users[available_columns].reset_index(drop=True),
                    use_container_width=True
                )
        
        # æ˜¾ç¤ºæœ€æœ‰å½±å“åŠ›ç”¨æˆ·
        if 'ç²‰ä¸æ•°' in user_activity.columns:
            top_influential_users = user_activity.nlargest(20, 'ç²‰ä¸æ•°')
            
            st.write("**æœ€æœ‰å½±å“åŠ›ç”¨æˆ·(å‰20)**")
            display_columns = ['æ˜µç§°', 'ç²‰ä¸æ•°', 'å…³æ³¨æ•°', 'å¾®åšæ•°']
            available_columns = [col for col in display_columns if col in top_influential_users.columns]
            
            if available_columns:
                st.dataframe(
                    top_influential_users[available_columns].reset_index(drop=True),
                    use_container_width=True
                )

def show_mention_network_analysis(df: pd.DataFrame, analyzer: SocialNetworkAnalyzer):
    """æ˜¾ç¤º@æåŠç½‘ç»œåˆ†æ"""
    st.subheader("ğŸ”— @æåŠç½‘ç»œåˆ†æ")
    
    # é€‰æ‹©æ–‡æœ¬åˆ—
    text_columns = [col for col in df.columns if 'å†…å®¹' in col]
    if not text_columns:
        st.error("âŒ æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°å†…å®¹å­—æ®µ")
        return
    
    text_column = st.selectbox("é€‰æ‹©æ–‡æœ¬å­—æ®µ", text_columns, index=0)
    
    # åˆ†æ@æåŠç½‘ç»œ
    mention_analysis = analyzer.analyze_mention_network(df, text_column)
    
    if 'error' in mention_analysis:
        st.error(f"âŒ {mention_analysis['error']}")
        return
    
    if mention_analysis.get('mentions_count', 0) == 0:
        st.warning("âš ï¸ æ•°æ®ä¸­æ²¡æœ‰å‘ç°@æåŠ")
        return
    
    # åŸºç¡€ç»Ÿè®¡
    st.subheader("ğŸ“Š @æåŠç»Ÿè®¡")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»æåŠæ¬¡æ•°", mention_analysis['mentions_count'])
    with col2:
        st.metric("æåŠè€…æ•°é‡", mention_analysis['unique_mentioners'])
    with col3:
        st.metric("è¢«æåŠè€…æ•°é‡", mention_analysis['unique_mentioned'])
    
    # ç½‘ç»œç»Ÿè®¡
    if 'network_stats' in mention_analysis:
        st.subheader("ğŸŒ ç½‘ç»œç»“æ„ç»Ÿè®¡")
        
        network_stats = mention_analysis['network_stats']
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ç½‘ç»œèŠ‚ç‚¹", network_stats['nodes'])
        with col2:
            st.metric("ç½‘ç»œè¾¹", network_stats['edges'])
        with col3:
            st.metric("ç½‘ç»œå¯†åº¦", f"{network_stats['density']:.4f}")
        with col4:
            connected_status = "æ˜¯" if network_stats.get('is_connected', False) else "å¦"
            st.metric("å¼±è¿é€š", connected_status)
    
    # æœ€å¸¸è¢«æåŠçš„ç”¨æˆ·
    if 'most_mentioned' in mention_analysis:
        st.subheader("ğŸ† æœ€å¸¸è¢«æåŠç”¨æˆ·")
        
        most_mentioned = mention_analysis['most_mentioned']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # è¢«æåŠæ¬¡æ•°æŸ±çŠ¶å›¾
            users = list(most_mentioned.keys())[:10]
            counts = [most_mentioned[user] for user in users]
            
            fig_mentioned = go.Figure(data=[
                go.Bar(
                    x=counts,
                    y=users,
                    orientation='h',
                    marker_color=analyzer.visualizer.color_palette[0],
                    text=counts,
                    textposition='auto'
                )
            ])
            fig_mentioned.update_layout(
                title="æœ€å¸¸è¢«æåŠç”¨æˆ·(å‰10)",
                xaxis_title="è¢«æåŠæ¬¡æ•°",
                yaxis_title="ç”¨æˆ·",
                height=400
            )
            st.plotly_chart(fig_mentioned, use_container_width=True)
        
        with col2:
            # è¢«æåŠç”¨æˆ·è¡¨æ ¼
            mentioned_data = []
            for user, count in list(most_mentioned.items())[:10]:
                mentioned_data.append({'ç”¨æˆ·': user, 'è¢«æåŠæ¬¡æ•°': count})
            
            mentioned_df = pd.DataFrame(mentioned_data)
            st.dataframe(mentioned_df, use_container_width=True)
    
    # æœ€æ´»è·ƒçš„æåŠè€…
    if 'most_mentioners' in mention_analysis:
        st.subheader("ğŸ“¢ æœ€æ´»è·ƒæåŠè€…")
        
        most_mentioners = mention_analysis['most_mentioners']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # æåŠæ¬¡æ•°æŸ±çŠ¶å›¾
            mentioners = list(most_mentioners.keys())[:10]
            counts = [most_mentioners[user] for user in mentioners]
            
            fig_mentioners = go.Figure(data=[
                go.Bar(
                    x=counts,
                    y=mentioners,
                    orientation='h',
                    marker_color=analyzer.visualizer.color_palette[1],
                    text=counts,
                    textposition='auto'
                )
            ])
            fig_mentioners.update_layout(
                title="æœ€æ´»è·ƒæåŠè€…(å‰10)",
                xaxis_title="æåŠæ¬¡æ•°",
                yaxis_title="ç”¨æˆ·",
                height=400
            )
            st.plotly_chart(fig_mentioners, use_container_width=True)
        
        with col2:
            # æåŠè€…è¡¨æ ¼
            mentioner_data = []
            for user, count in list(most_mentioners.items())[:10]:
                mentioner_data.append({'ç”¨æˆ·': user, 'æåŠæ¬¡æ•°': count})
            
            mentioner_df = pd.DataFrame(mentioner_data)
            st.dataframe(mentioner_df, use_container_width=True)
    
    # ä¸­å¿ƒæ€§åˆ†æ
    if 'centrality' in mention_analysis:
        st.subheader("ğŸ¯ ç½‘ç»œä¸­å¿ƒæ€§åˆ†æ")
        
        centrality = mention_analysis['centrality']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**å…¥åº¦ä¸­å¿ƒæ€§(å½±å“åŠ›)**")
            in_degree_data = []
            for user, score in list(centrality['top_in_degree'].items())[:10]:
                in_degree_data.append({'ç”¨æˆ·': user, 'å…¥åº¦ä¸­å¿ƒæ€§': f"{score:.4f}"})
            
            if in_degree_data:
                in_degree_df = pd.DataFrame(in_degree_data)
                st.dataframe(in_degree_df, use_container_width=True)
        
        with col2:
            st.write("**å‡ºåº¦ä¸­å¿ƒæ€§(æ´»è·ƒåº¦)**")
            out_degree_data = []
            for user, score in list(centrality['top_out_degree'].items())[:10]:
                out_degree_data.append({'ç”¨æˆ·': user, 'å‡ºåº¦ä¸­å¿ƒæ€§': f"{score:.4f}"})
            
            if out_degree_data:
                out_degree_df = pd.DataFrame(out_degree_data)
                st.dataframe(out_degree_df, use_container_width=True)
    
    # ç½‘ç»œå¯è§†åŒ–
    if 'network_viz' in mention_analysis:
        st.subheader("ğŸ•¸ï¸ ç½‘ç»œå¯è§†åŒ–")
        
        viz_data = mention_analysis['network_viz']
        
        # åˆ›å»ºç½‘ç»œå›¾
        fig_network = go.Figure()
        
        # æ·»åŠ è¾¹
        fig_network.add_trace(go.Scatter(
            x=viz_data['edge_x'],
            y=viz_data['edge_y'],
            mode='lines',
            line=dict(width=0.5, color='#888'),
            hoverinfo='none',
            showlegend=False
        ))
        
        # æ·»åŠ èŠ‚ç‚¹
        fig_network.add_trace(go.Scatter(
            x=viz_data['node_x'],
            y=viz_data['node_y'],
            mode='markers+text',
            marker=dict(
                size=viz_data['node_size'],
                color=analyzer.visualizer.color_palette[0],
                line=dict(width=2, color='white')
            ),
            text=[text.split('<br>')[0] for text in viz_data['node_text']],  # åªæ˜¾ç¤ºç”¨æˆ·å
            textposition="middle center",
            hovertext=viz_data['node_text'],
            hoverinfo='text',
            showlegend=False
        ))
        
        fig_network.update_layout(
            title="@æåŠç½‘ç»œå›¾",
            showlegend=False,
            hovermode='closest',
            margin=dict(b=20,l=5,r=5,t=40),
            annotations=[
                dict(
                    text="èŠ‚ç‚¹å¤§å°è¡¨ç¤ºè¢«æåŠæ¬¡æ•°ï¼Œè¿çº¿è¡¨ç¤ºæåŠå…³ç³»",
                    showarrow=False,
                    xref="paper", yref="paper",
                    x=0.005, y=-0.002,
                    xanchor='left', yanchor='bottom',
                    font=dict(size=12)
                )
            ],
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
        )
        
        st.plotly_chart(fig_network, use_container_width=True)
        
        # ç½‘ç»œæ´å¯Ÿ
        st.subheader("ğŸ’¡ ç½‘ç»œæ´å¯Ÿ")
        
        network_insights = [
            f"ğŸŒ ç½‘ç»œåŒ…å«{mention_analysis['network_stats']['nodes']}ä¸ªç”¨æˆ·èŠ‚ç‚¹",
            f"ğŸ”— å…±æœ‰{mention_analysis['network_stats']['edges']}æ¡æåŠå…³ç³»",
            f"ğŸ“Š ç½‘ç»œå¯†åº¦ä¸º{mention_analysis['network_stats']['density']:.4f}ï¼Œè¡¨ç¤ºè¿æ¥ç¨‹åº¦",
            f"ğŸ‘‘ æœ€æœ‰å½±å“åŠ›çš„ç”¨æˆ·æ˜¯è¢«æåŠæœ€å¤šçš„ç”¨æˆ·",
            f"ğŸ“¢ æœ€æ´»è·ƒçš„ç”¨æˆ·æ˜¯æåŠä»–äººæœ€å¤šçš„ç”¨æˆ·"
        ]
        
        for insight in network_insights:
            st.info(insight)

def show_follower_pattern_analysis(df: pd.DataFrame, analyzer: SocialNetworkAnalyzer):
    """æ˜¾ç¤ºå…³æ³¨è€…æ¨¡å¼åˆ†æ"""
    st.subheader("ğŸ‘¥ å…³æ³¨è€…æ¨¡å¼åˆ†æ")
    
    # åˆ†æå…³æ³¨è€…æ¨¡å¼
    follower_analysis = analyzer.analyze_follower_patterns(df)
    
    if 'error' in follower_analysis:
        st.error(f"âŒ {follower_analysis['error']}")
        return
    
    # åŸºç¡€ç»Ÿè®¡
    if 'basic_stats' in follower_analysis:
        st.subheader("ğŸ“Š å…³æ³¨/ç²‰ä¸ç»Ÿè®¡")
        
        stats = follower_analysis['basic_stats']
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("åˆ†æç”¨æˆ·æ•°", stats['total_users'])
        with col2:
            st.metric("å¹³å‡å…³æ³¨æ•°", f"{stats['avg_following']:.0f}")
        with col3:
            st.metric("å¹³å‡ç²‰ä¸æ•°", f"{stats['avg_followers']:.0f}")
        with col4:
            correlation = follower_analysis.get('following_followers_correlation', 0)
            st.metric("å…³æ³¨ç²‰ä¸ç›¸å…³æ€§", f"{correlation:.3f}")
        
        # æœ€å¤§å€¼ç»Ÿè®¡
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æœ€å¤§å…³æ³¨æ•°", f"{stats['max_following']:,}")
        with col2:
            st.metric("æœ€å¤§ç²‰ä¸æ•°", f"{stats['max_followers']:,}")
    
    # ç”¨æˆ·ç±»å‹åˆ†å¸ƒ
    if 'user_type_distribution' in follower_analysis:
        st.subheader("ğŸ‘¤ ç”¨æˆ·ç±»å‹åˆ†å¸ƒ")
        
        user_types = follower_analysis['user_type_distribution']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ç”¨æˆ·ç±»å‹æŸ±çŠ¶å›¾
            fig_types = go.Figure(data=[
                go.Bar(
                    x=list(user_types.keys()),
                    y=list(user_types.values()),
                    marker_color=analyzer.visualizer.color_palette[0],
                    text=list(user_types.values()),
                    textposition='auto'
                )
            ])
            fig_types.update_layout(
                title="ç”¨æˆ·ç±»å‹åˆ†å¸ƒ",
                xaxis_title="ç”¨æˆ·ç±»å‹",
                yaxis_title="ç”¨æˆ·æ•°é‡",
                xaxis_tickangle=-45
            )
            st.plotly_chart(fig_types, use_container_width=True)
        
        with col2:
            # ç”¨æˆ·ç±»å‹é¥¼å›¾
            fig_types_pie = go.Figure(data=[
                go.Pie(
                    labels=list(user_types.keys()),
                    values=list(user_types.values()),
                    hole=0.3
                )
            ])
            fig_types_pie.update_layout(title="ç”¨æˆ·ç±»å‹å æ¯”")
            st.plotly_chart(fig_types_pie, use_container_width=True)
    
    # å…³æ³¨ç²‰ä¸æ¯”åˆ†å¸ƒ
    if 'ratio_distribution' in follower_analysis:
        st.subheader("âš–ï¸ å…³æ³¨ç²‰ä¸æ¯”åˆ†å¸ƒ")
        
        ratio_dist = follower_analysis['ratio_distribution']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # æ¯”ä¾‹åˆ†å¸ƒæŸ±çŠ¶å›¾
            fig_ratio = go.Figure(data=[
                go.Bar(
                    x=list(ratio_dist.keys()),
                    y=list(ratio_dist.values()),
                    marker_color=analyzer.visualizer.color_palette[1],
                    text=list(ratio_dist.values()),
                    textposition='auto'
                )
            ])
            fig_ratio.update_layout(
                title="å…³æ³¨ç²‰ä¸æ¯”åˆ†å¸ƒ",
                xaxis_title="æ¯”ä¾‹ç±»å‹",
                yaxis_title="ç”¨æˆ·æ•°é‡",
                xaxis_tickangle=-45
            )
            st.plotly_chart(fig_ratio, use_container_width=True)
        
        with col2:
            # æ¯”ä¾‹åˆ†å¸ƒé¥¼å›¾
            fig_ratio_pie = go.Figure(data=[
                go.Pie(
                    labels=list(ratio_dist.keys()),
                    values=list(ratio_dist.values()),
                    hole=0.3
                )
            ])
            fig_ratio_pie.update_layout(title="å…³æ³¨ç²‰ä¸æ¯”å æ¯”")
            st.plotly_chart(fig_ratio_pie, use_container_width=True)
    
    # å½±å“åŠ›åˆ†å¸ƒ
    if 'influence_distribution' in follower_analysis:
        st.subheader("â­ å½±å“åŠ›åˆ†å¸ƒ")
        
        influence_dist = follower_analysis['influence_distribution']
        
        # å½±å“åŠ›é‡‘å­—å¡”å›¾
        fig_influence = go.Figure(data=[
            go.Bar(
                x=list(influence_dist.keys()),
                y=list(influence_dist.values()),
                marker_color=analyzer.visualizer.color_palette[2],
                text=list(influence_dist.values()),
                textposition='auto'
            )
        ])
        fig_influence.update_layout(
            title="ç”¨æˆ·å½±å“åŠ›åˆ†å¸ƒ",
            xaxis_title="å½±å“åŠ›ç­‰çº§",
            yaxis_title="ç”¨æˆ·æ•°é‡"
        )
        st.plotly_chart(fig_influence, use_container_width=True)
        
        # å½±å“åŠ›æ´å¯Ÿ
        total_users = sum(influence_dist.values())
        if total_users > 0:
            kol_ratio = influence_dist.get('è¶…çº§å½±å“è€…', 0) / total_users * 100
            high_influence_ratio = influence_dist.get('é«˜å½±å“è€…', 0) / total_users * 100
            
            insights = [
                f"ğŸ‘‘ è¶…çº§å½±å“è€…å æ¯”ï¼š{kol_ratio:.1f}%",
                f"â­ é«˜å½±å“è€…å æ¯”ï¼š{high_influence_ratio:.1f}%",
                f"ğŸ“Š å½±å“åŠ›å‘ˆç°é‡‘å­—å¡”åˆ†å¸ƒï¼Œç¬¦åˆç¤¾äº¤ç½‘ç»œç‰¹å¾"
            ]
            
            for insight in insights:
                st.info(insight)
    
    # å¼‚å¸¸å€¼åˆ†æ
    if 'outliers' in follower_analysis:
        st.subheader("ğŸ” å¼‚å¸¸å€¼åˆ†æ")
        
        outliers = follower_analysis['outliers']
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å¼‚å¸¸ç”¨æˆ·æ€»æ•°", outliers['count'])
        with col2:
            st.metric("é«˜å…³æ³¨ç”¨æˆ·", outliers['high_following'])
        with col3:
            st.metric("é«˜ç²‰ä¸ç”¨æˆ·", outliers['high_followers'])
        
        if outliers['count'] > 0:
            st.info(f"ğŸ” å‘ç°{outliers['count']}ä¸ªå¼‚å¸¸ç”¨æˆ·ï¼Œå¯èƒ½æ˜¯æœºå™¨äººè´¦å·æˆ–ç‰¹æ®Šç”¨æˆ·")

def show_interaction_intensity_analysis(df: pd.DataFrame, analyzer: SocialNetworkAnalyzer):
    """æ˜¾ç¤ºäº’åŠ¨å¼ºåº¦åˆ†æ"""
    st.subheader("ğŸ”¥ äº’åŠ¨å¼ºåº¦åˆ†æ")
    
    # åˆ†æäº’åŠ¨å¼ºåº¦
    intensity_analysis = analyzer.analyze_interaction_intensity(df)
    
    if 'error' in intensity_analysis:
        st.error(f"âŒ {intensity_analysis['error']}")
        return
    
    # åŸºç¡€ç»Ÿè®¡
    if 'basic_stats' in intensity_analysis:
        st.subheader("ğŸ“Š äº’åŠ¨ç»Ÿè®¡")
        
        stats = intensity_analysis['basic_stats']
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»å†…å®¹æ•°", stats['total_posts'])
        with col2:
            st.metric("å¹³å‡@æåŠ", f"{stats['avg_mentions']:.2f}")
        with col3:
            st.metric("å¹³å‡è¯é¢˜æ ‡ç­¾", f"{stats['avg_hashtags']:.2f}")
        with col4:
            st.metric("å¹³å‡é“¾æ¥", f"{stats['avg_urls']:.2f}")
        
        st.metric("å¹³å‡äº’åŠ¨å¾—åˆ†", f"{stats['avg_interaction_score']:.2f}")
    
    # äº’åŠ¨å¼ºåº¦åˆ†å¸ƒ
    if 'intensity_distribution' in intensity_analysis:
        st.subheader("ğŸ“ˆ äº’åŠ¨å¼ºåº¦åˆ†å¸ƒ")
        
        intensity_dist = intensity_analysis['intensity_distribution']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å¼ºåº¦åˆ†å¸ƒæŸ±çŠ¶å›¾
            fig_intensity = go.Figure(data=[
                go.Bar(
                    x=list(intensity_dist.keys()),
                    y=list(intensity_dist.values()),
                    marker_color=analyzer.visualizer.color_palette[0],
                    text=list(intensity_dist.values()),
                    textposition='auto'
                )
            ])
            fig_intensity.update_layout(
                title="äº’åŠ¨å¼ºåº¦åˆ†å¸ƒ",
                xaxis_title="äº’åŠ¨å¼ºåº¦",
                yaxis_title="å†…å®¹æ•°é‡"
            )
            st.plotly_chart(fig_intensity, use_container_width=True)
        
        with col2:
            # å¼ºåº¦åˆ†å¸ƒé¥¼å›¾
            fig_intensity_pie = go.Figure(data=[
                go.Pie(
                    labels=list(intensity_dist.keys()),
                    values=list(intensity_dist.values()),
                    hole=0.3
                )
            ])
            fig_intensity_pie.update_layout(title="äº’åŠ¨å¼ºåº¦å æ¯”")
            st.plotly_chart(fig_intensity_pie, use_container_width=True)
    
    # æœ€æ´»è·ƒäº’åŠ¨ç”¨æˆ·
    if 'top_interactive_users' in intensity_analysis:
        st.subheader("ğŸ† æœ€æ´»è·ƒäº’åŠ¨ç”¨æˆ·")
        
        top_users = intensity_analysis['top_interactive_users']
        
        if top_users:
            # è½¬æ¢ä¸ºDataFrameæ˜¾ç¤º
            top_users_df = pd.DataFrame(top_users)
            
            # é‡å‘½ååˆ—
            column_mapping = {
                'user_name': 'ç”¨æˆ·å',
                'mentions': '@æåŠæ•°',
                'hashtags': 'è¯é¢˜æ ‡ç­¾æ•°',
                'urls': 'é“¾æ¥æ•°',
                'interaction_score': 'äº’åŠ¨å¾—åˆ†'
            }
            
            display_columns = [col for col in column_mapping.keys() if col in top_users_df.columns]
            top_users_display = top_users_df[display_columns].rename(columns=column_mapping)
            
            st.dataframe(top_users_display, use_container_width=True)
            
            # å¯è§†åŒ–å‰10ç”¨æˆ·çš„äº’åŠ¨å¾—åˆ†
            if len(top_users) > 0:
                top_10 = top_users[:10]
                
                fig_top_users = go.Figure(data=[
                    go.Bar(
                        x=[user['interaction_score'] for user in top_10],
                        y=[user['user_name'] for user in top_10],
                        orientation='h',
                        marker_color=analyzer.visualizer.color_palette[1],
                        text=[user['interaction_score'] for user in top_10],
                        textposition='auto'
                    )
                ])
                fig_top_users.update_layout(
                    title="æœ€æ´»è·ƒäº’åŠ¨ç”¨æˆ·(å‰10)",
                    xaxis_title="äº’åŠ¨å¾—åˆ†",
                    yaxis_title="ç”¨æˆ·",
                    height=400
                )
                st.plotly_chart(fig_top_users, use_container_width=True)
    
    # äº’åŠ¨ç±»å‹åå¥½
    if 'interaction_preferences' in intensity_analysis:
        st.subheader("ğŸ¯ äº’åŠ¨ç±»å‹åå¥½")
        
        preferences = intensity_analysis['interaction_preferences']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # åå¥½æŸ±çŠ¶å›¾
            pref_labels = {'mentions': '@æåŠ', 'hashtags': 'è¯é¢˜æ ‡ç­¾', 'urls': 'é“¾æ¥åˆ†äº«'}
            labels = [pref_labels.get(k, k) for k in preferences.keys()]
            values = list(preferences.values())
            
            fig_pref = go.Figure(data=[
                go.Bar(
                    x=labels,
                    y=values,
                    marker_color=analyzer.visualizer.color_palette[2],
                    text=[f"{v:.1f}%" for v in values],
                    textposition='auto'
                )
            ])
            fig_pref.update_layout(
                title="äº’åŠ¨ç±»å‹åå¥½",
                xaxis_title="äº’åŠ¨ç±»å‹",
                yaxis_title="å æ¯”(%)"
            )
            st.plotly_chart(fig_pref, use_container_width=True)
        
        with col2:
            # åå¥½é¥¼å›¾
            fig_pref_pie = go.Figure(data=[
                go.Pie(
                    labels=labels,
                    values=values,
                    hole=0.3
                )
            ])
            fig_pref_pie.update_layout(title="äº’åŠ¨ç±»å‹åˆ†å¸ƒ")
            st.plotly_chart(fig_pref_pie, use_container_width=True)
    
    # äº’åŠ¨ä¸æ–‡æœ¬é•¿åº¦å…³ç³»
    if 'length_interaction_correlation' in intensity_analysis:
        st.subheader("ğŸ“ äº’åŠ¨ä¸æ–‡æœ¬é•¿åº¦å…³ç³»")
        
        correlation = intensity_analysis['length_interaction_correlation']
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.metric("ç›¸å…³ç³»æ•°", f"{correlation:.3f}")
            
            if correlation > 0.3:
                st.success("ğŸ“ˆ å¼ºæ­£ç›¸å…³ï¼šé•¿æ–‡æœ¬å€¾å‘äºæœ‰æ›´å¤šäº’åŠ¨")
            elif correlation > 0.1:
                st.info("ğŸ“Š å¼±æ­£ç›¸å…³ï¼šæ–‡æœ¬é•¿åº¦ä¸äº’åŠ¨æœ‰ä¸€å®šå…³ç³»")
            elif correlation < -0.1:
                st.warning("ğŸ“‰ è´Ÿç›¸å…³ï¼šçŸ­æ–‡æœ¬å¯èƒ½æœ‰æ›´å¤šäº’åŠ¨")
            else:
                st.info("â¡ï¸ æ— æ˜æ˜¾ç›¸å…³æ€§")
        
        with col2:
            # ç›¸å…³æ€§è§£é‡Š
            correlation_insights = [
                f"ğŸ“Š æ–‡æœ¬é•¿åº¦ä¸äº’åŠ¨å¼ºåº¦çš„ç›¸å…³ç³»æ•°ä¸º{correlation:.3f}",
                "ğŸ“ æ­£ç›¸å…³è¡¨ç¤ºé•¿æ–‡æœ¬é€šå¸¸åŒ…å«æ›´å¤šäº’åŠ¨å…ƒç´ ",
                "ğŸ’¬ è´Ÿç›¸å…³è¡¨ç¤ºçŸ­æ–‡æœ¬å¯èƒ½æ›´å®¹æ˜“å¼•èµ·äº’åŠ¨",
                "ğŸ¯ å¯ä»¥æ ¹æ®æ­¤å…³ç³»ä¼˜åŒ–å†…å®¹ç­–ç•¥"
            ]
            
            for insight in correlation_insights:
                st.caption(insight)

def show_social_network_report(df: pd.DataFrame, analyzer: SocialNetworkAnalyzer):
    """æ˜¾ç¤ºç¤¾äº¤ç½‘ç»œç»¼åˆæŠ¥å‘Š"""
    st.subheader("ğŸ“‹ ç¤¾äº¤ç½‘ç»œç»¼åˆæŠ¥å‘Š")
    
    # è·å–æ‰€æœ‰åˆ†æç»“æœ
    interaction_analysis = analyzer.analyze_user_interactions(df)
    follower_analysis = analyzer.analyze_follower_patterns(df)
    intensity_analysis = analyzer.analyze_interaction_intensity(df)
    
    # æ£€æŸ¥æ–‡æœ¬å­—æ®µç”¨äº@æåŠåˆ†æ
    text_columns = [col for col in df.columns if 'å†…å®¹' in col]
    mention_analysis = {}
    if text_columns:
        mention_analysis = analyzer.analyze_mention_network(df, text_columns[0])
    
    # å…³é”®æŒ‡æ ‡æ¦‚è§ˆ
    st.subheader("ğŸ“Š å…³é”®æŒ‡æ ‡æ¦‚è§ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if 'basic_stats' in interaction_analysis:
            unique_users = interaction_analysis['basic_stats']['unique_users']
            st.metric("æ´»è·ƒç”¨æˆ·æ•°", unique_users)
    
    with col2:
        if 'basic_stats' in follower_analysis:
            avg_followers = follower_analysis['basic_stats']['avg_followers']
            st.metric("å¹³å‡ç²‰ä¸æ•°", f"{avg_followers:.0f}")
    
    with col3:
        if mention_analysis and 'mentions_count' in mention_analysis:
            mentions_count = mention_analysis['mentions_count']
            st.metric("@æåŠæ€»æ•°", mentions_count)
    
    with col4:
        if 'basic_stats' in intensity_analysis:
            avg_score = intensity_analysis['basic_stats']['avg_interaction_score']
            st.metric("å¹³å‡äº’åŠ¨å¾—åˆ†", f"{avg_score:.2f}")
    
    # ç¤¾äº¤ç½‘ç»œç‰¹å¾æ€»ç»“
    st.subheader("ğŸŒ ç¤¾äº¤ç½‘ç»œç‰¹å¾")
    
    network_insights = []
    
    # ç”¨æˆ·æ´»è·ƒåº¦ç‰¹å¾
    if 'activity_distribution' in interaction_analysis:
        activity_dist = interaction_analysis['activity_distribution']
        total_users = sum(activity_dist.values())
        
        if total_users > 0:
            super_active = activity_dist.get('è¶…çº§æ´»è·ƒ', 0) / total_users * 100
            if super_active > 20:
                network_insights.append(f"ğŸ”¥ é«˜æ´»è·ƒåº¦ç½‘ç»œï¼š{super_active:.1f}%çš„ç”¨æˆ·ä¸ºè¶…çº§æ´»è·ƒç”¨æˆ·")
            elif super_active > 10:
                network_insights.append(f"ğŸ“Š ä¸­ç­‰æ´»è·ƒåº¦ç½‘ç»œï¼š{super_active:.1f}%çš„ç”¨æˆ·ä¸ºè¶…çº§æ´»è·ƒç”¨æˆ·")
            else:
                network_insights.append(f"ğŸ˜´ ä½æ´»è·ƒåº¦ç½‘ç»œï¼šä»…{super_active:.1f}%çš„ç”¨æˆ·ä¸ºè¶…çº§æ´»è·ƒç”¨æˆ·")
    
    # å½±å“åŠ›åˆ†å¸ƒç‰¹å¾
    if 'influence_distribution' in follower_analysis:
        influence_dist = follower_analysis['influence_distribution']
        total_users = sum(influence_dist.values())
        
        if total_users > 0:
            kol_ratio = influence_dist.get('è¶…çº§å½±å“è€…', 0) / total_users * 100
            if kol_ratio > 5:
                network_insights.append(f"ğŸ‘‘ KOLå¯†é›†å‹ç½‘ç»œï¼š{kol_ratio:.1f}%çš„ç”¨æˆ·å…·æœ‰è¶…çº§å½±å“åŠ›")
            else:
                network_insights.append(f"ğŸ‘¥ å¹³æ°‘åŒ–ç½‘ç»œï¼šä»…{kol_ratio:.1f}%çš„ç”¨æˆ·å…·æœ‰è¶…çº§å½±å“åŠ›")
    
    # äº’åŠ¨æ¨¡å¼ç‰¹å¾
    if 'intensity_distribution' in intensity_analysis:
        intensity_dist = intensity_analysis['intensity_distribution']
        total_posts = sum(intensity_dist.values())
        
        if total_posts > 0:
            high_interaction = intensity_dist.get('é«˜äº’åŠ¨', 0) + intensity_dist.get('è¶…é«˜äº’åŠ¨', 0)
            high_ratio = high_interaction / total_posts * 100
            
            if high_ratio > 30:
                network_insights.append(f"ğŸ”¥ é«˜äº’åŠ¨ç½‘ç»œï¼š{high_ratio:.1f}%çš„å†…å®¹å…·æœ‰é«˜äº’åŠ¨æ€§")
            elif high_ratio > 15:
                network_insights.append(f"ğŸ“Š ä¸­ç­‰äº’åŠ¨ç½‘ç»œï¼š{high_ratio:.1f}%çš„å†…å®¹å…·æœ‰é«˜äº’åŠ¨æ€§")
            else:
                network_insights.append(f"ğŸ˜ ä½äº’åŠ¨ç½‘ç»œï¼šä»…{high_ratio:.1f}%çš„å†…å®¹å…·æœ‰é«˜äº’åŠ¨æ€§")
    
    # ç½‘ç»œè¿é€šæ€§ç‰¹å¾
    if mention_analysis and 'network_stats' in mention_analysis:
        network_stats = mention_analysis['network_stats']
        density = network_stats.get('density', 0)
        
        if density > 0.1:
            network_insights.append(f"ğŸ•¸ï¸ é«˜å¯†åº¦ç½‘ç»œï¼šç½‘ç»œå¯†åº¦ä¸º{density:.4f}ï¼Œç”¨æˆ·é—´è”ç³»ç´§å¯†")
        elif density > 0.01:
            network_insights.append(f"ğŸ”— ä¸­å¯†åº¦ç½‘ç»œï¼šç½‘ç»œå¯†åº¦ä¸º{density:.4f}ï¼Œç”¨æˆ·é—´æœ‰ä¸€å®šè”ç³»")
        else:
            network_insights.append(f"ğŸŒŒ ç¨€ç–ç½‘ç»œï¼šç½‘ç»œå¯†åº¦ä¸º{density:.4f}ï¼Œç”¨æˆ·é—´è”ç³»è¾ƒå°‘")
    
    # æ˜¾ç¤ºç½‘ç»œæ´å¯Ÿ
    if network_insights:
        for insight in network_insights:
            st.info(insight)
    
    # ç½‘ç»œå¥åº·åº¦è¯„ä¼°
    st.subheader("ğŸ’Š ç½‘ç»œå¥åº·åº¦è¯„ä¼°")
    
    health_score = 0
    health_factors = []
    
    # æ´»è·ƒåº¦è¯„åˆ†
    if 'activity_distribution' in interaction_analysis:
        activity_dist = interaction_analysis['activity_distribution']
        total_users = sum(activity_dist.values())
        
        if total_users > 0:
            active_ratio = (activity_dist.get('é«˜åº¦æ´»è·ƒ', 0) + activity_dist.get('è¶…çº§æ´»è·ƒ', 0)) / total_users
            activity_score = min(active_ratio * 100, 25)  # æœ€é«˜25åˆ†
            health_score += activity_score
            health_factors.append(f"ç”¨æˆ·æ´»è·ƒåº¦ï¼š{activity_score:.1f}/25")
    
    # å½±å“åŠ›åˆ†å¸ƒè¯„åˆ†
    if 'influence_distribution' in follower_analysis:
        influence_dist = follower_analysis['influence_distribution']
        total_users = sum(influence_dist.values())
        
        if total_users > 0:
            # ç†æƒ³çš„å½±å“åŠ›åˆ†å¸ƒåº”è¯¥æ˜¯é‡‘å­—å¡”å‹
            kol_ratio = influence_dist.get('è¶…çº§å½±å“è€…', 0) / total_users
            high_ratio = influence_dist.get('é«˜å½±å“è€…', 0) / total_users
            
            # è¯„åˆ†é€»è¾‘ï¼šKOLä¸èƒ½å¤ªå¤šä¹Ÿä¸èƒ½å¤ªå°‘ï¼Œé«˜å½±å“è€…åº”è¯¥é€‚ä¸­
            if 0.01 <= kol_ratio <= 0.05 and 0.05 <= high_ratio <= 0.15:
                influence_score = 25
            elif 0.005 <= kol_ratio <= 0.1 and 0.03 <= high_ratio <= 0.2:
                influence_score = 20
            else:
                influence_score = 15
            
            health_score += influence_score
            health_factors.append(f"å½±å“åŠ›åˆ†å¸ƒï¼š{influence_score}/25")
    
    # äº’åŠ¨æ´»è·ƒåº¦è¯„åˆ†
    if 'intensity_distribution' in intensity_analysis:
        intensity_dist = intensity_analysis['intensity_distribution']
        total_posts = sum(intensity_dist.values())
        
        if total_posts > 0:
            interactive_ratio = (intensity_dist.get('ä¸­ç­‰äº’åŠ¨', 0) + 
                               intensity_dist.get('é«˜äº’åŠ¨', 0) + 
                               intensity_dist.get('è¶…é«˜äº’åŠ¨', 0)) / total_posts
            interaction_score = min(interactive_ratio * 50, 25)  # æœ€é«˜25åˆ†
            health_score += interaction_score
            health_factors.append(f"äº’åŠ¨æ´»è·ƒåº¦ï¼š{interaction_score:.1f}/25")
    
    # ç½‘ç»œè¿é€šæ€§è¯„åˆ†
    if mention_analysis and 'network_stats' in mention_analysis:
        network_stats = mention_analysis['network_stats']
        density = network_stats.get('density', 0)
        
        # å¯†åº¦è¯„åˆ†
        if density > 0.05:
            connectivity_score = 25
        elif density > 0.01:
            connectivity_score = 20
        elif density > 0.001:
            connectivity_score = 15
        else:
            connectivity_score = 10
        
        health_score += connectivity_score
        health_factors.append(f"ç½‘ç»œè¿é€šæ€§ï¼š{connectivity_score}/25")
    
    # æ˜¾ç¤ºå¥åº·åº¦è¯„åˆ†
    col1, col2 = st.columns([1, 2])
    
    with col1:
        # å¥åº·åº¦ä»ªè¡¨ç›˜
        fig_health = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = health_score,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "ç½‘ç»œå¥åº·åº¦"},
            delta = {'reference': 80},
            gauge = {
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 50], 'color': "lightgray"},
                    {'range': [50, 80], 'color': "yellow"},
                    {'range': [80, 100], 'color': "green"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        fig_health.update_layout(height=300)
        st.plotly_chart(fig_health, use_container_width=True)
    
    with col2:
        # å¥åº·åº¦å› å­è¯¦æƒ…
        st.write("**å¥åº·åº¦è¯„åˆ†è¯¦æƒ…ï¼š**")
        for factor in health_factors:
            st.write(f"â€¢ {factor}")
        
        # å¥åº·åº¦ç­‰çº§
        if health_score >= 80:
            st.success(f"ğŸŒŸ ä¼˜ç§€ç½‘ç»œ ({health_score:.1f}/100)")
            st.write("ç½‘ç»œæ´»è·ƒåº¦é«˜ï¼Œç”¨æˆ·å‚ä¸åº¦å¼ºï¼Œå½±å“åŠ›åˆ†å¸ƒåˆç†")
        elif health_score >= 60:
            st.info(f"ğŸ‘ è‰¯å¥½ç½‘ç»œ ({health_score:.1f}/100)")
            st.write("ç½‘ç»œè¿è¡Œè‰¯å¥½ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´")
        elif health_score >= 40:
            st.warning(f"âš ï¸ ä¸€èˆ¬ç½‘ç»œ ({health_score:.1f}/100)")
            st.write("ç½‘ç»œå­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œéœ€è¦å…³æ³¨å’Œæ”¹è¿›")
        else:
            st.error(f"âŒ å¾…æ”¹å–„ç½‘ç»œ ({health_score:.1f}/100)")
            st.write("ç½‘ç»œæ´»è·ƒåº¦ä½ï¼Œéœ€è¦é‡‡å–æªæ–½æå‡ç”¨æˆ·å‚ä¸åº¦")
    
    # æ”¹è¿›å»ºè®®
    st.subheader("ğŸ’¡ ç½‘ç»œä¼˜åŒ–å»ºè®®")
    
    suggestions = []
    
    # åŸºäºæ´»è·ƒåº¦çš„å»ºè®®
    if 'activity_distribution' in interaction_analysis:
        activity_dist = interaction_analysis['activity_distribution']
        total_users = sum(activity_dist.values())
        
        if total_users > 0:
            low_active = activity_dist.get('ä½åº¦æ´»è·ƒ', 0) / total_users
            if low_active > 0.5:
                suggestions.append("ğŸ“ˆ æå‡ç”¨æˆ·æ´»è·ƒåº¦ï¼šè€ƒè™‘æ¨å‡ºæ¿€åŠ±æœºåˆ¶ï¼Œé¼“åŠ±ç”¨æˆ·æ›´å¤šå‚ä¸")
    
    # åŸºäºå½±å“åŠ›çš„å»ºè®®
    if 'influence_distribution' in follower_analysis:
        influence_dist = follower_analysis['influence_distribution']
        total_users = sum(influence_dist.values())
        
        if total_users > 0:
            kol_ratio = influence_dist.get('è¶…çº§å½±å“è€…', 0) / total_users
            if kol_ratio < 0.01:
                suggestions.append("ğŸ‘‘ åŸ¹å…»æ„è§é¢†è¢–ï¼šè¯†åˆ«å’ŒåŸ¹å…»æ½œåœ¨çš„KOLç”¨æˆ·")
            elif kol_ratio > 0.1:
                suggestions.append("âš–ï¸ å¹³è¡¡å½±å“åŠ›ï¼šé¿å…è¿‡åº¦ä¾èµ–å°‘æ•°KOLç”¨æˆ·")
    
    # åŸºäºäº’åŠ¨çš„å»ºè®®
    if 'intensity_distribution' in intensity_analysis:
        intensity_dist = intensity_analysis['intensity_distribution']
        total_posts = sum(intensity_dist.values())
        
        if total_posts > 0:
            no_interaction = intensity_dist.get('æ— äº’åŠ¨', 0) / total_posts
            if no_interaction > 0.6:
                suggestions.append("ğŸ’¬ ä¿ƒè¿›ç”¨æˆ·äº’åŠ¨ï¼šä¼˜åŒ–å†…å®¹æ¨èç®—æ³•ï¼Œå¢åŠ äº’åŠ¨åŠŸèƒ½")
    
    # åŸºäºç½‘ç»œè¿é€šæ€§çš„å»ºè®®
    if mention_analysis and 'network_stats' in mention_analysis:
        network_stats = mention_analysis['network_stats']
        density = network_stats.get('density', 0)
        
        if density < 0.001:
            suggestions.append("ğŸ”— å¢å¼ºç½‘ç»œè¿æ¥ï¼šæ¨å‡ºè¯é¢˜è®¨è®ºã€ç”¨æˆ·æ¨èç­‰åŠŸèƒ½")
    
    # æ˜¾ç¤ºå»ºè®®
    if suggestions:
        for suggestion in suggestions:
            st.info(suggestion)
    else:
        st.success("ğŸ‰ ç½‘ç»œè¿è¡Œè‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰ç­–ç•¥ï¼")
    
    # æ•°æ®å¯¼å‡ºé€‰é¡¹
    st.subheader("ğŸ“¤ æ•°æ®å¯¼å‡º")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("å¯¼å‡ºç”¨æˆ·äº’åŠ¨æ•°æ®"):
            if 'user_activity' in interaction_analysis:
                user_data = interaction_analysis['user_activity']
                csv = user_data.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ä¸‹è½½CSVæ–‡ä»¶",
                    data=csv,
                    file_name="user_interaction_data.csv",
                    mime="text/csv"
                )
    
    with col2:
        if st.button("å¯¼å‡ºç½‘ç»œç»Ÿè®¡æŠ¥å‘Š"):
            report_data = {
                'æŒ‡æ ‡': [],
                'æ•°å€¼': []
            }
            
            # æ”¶é›†æ‰€æœ‰ç»Ÿè®¡æ•°æ®
            if 'basic_stats' in interaction_analysis:
                stats = interaction_analysis['basic_stats']
                for key, value in stats.items():
                    report_data['æŒ‡æ ‡'].append(f"ç”¨æˆ·äº’åŠ¨_{key}")
                    report_data['æ•°å€¼'].append(value)
            
            if 'basic_stats' in follower_analysis:
                stats = follower_analysis['basic_stats']
                for key, value in stats.items():
                    report_data['æŒ‡æ ‡'].append(f"å…³æ³¨æ¨¡å¼_{key}")
                    report_data['æ•°å€¼'].append(value)
            
            if report_data['æŒ‡æ ‡']:
                report_df = pd.DataFrame(report_data)
                csv = report_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ä¸‹è½½ç»Ÿè®¡æŠ¥å‘Š",
                    data=csv,
                    file_name="network_statistics_report.csv",
                    mime="text/csv"
                )
    
    with col3:
        if st.button("å¯¼å‡ºå¥åº·åº¦è¯„ä¼°"):
            health_data = {
                'è¯„ä¼°é¡¹ç›®': health_factors,
                'æ€»ä½“å¥åº·åº¦': [f"{health_score:.1f}/100"] + [''] * (len(health_factors) - 1)
            }
            
            health_df = pd.DataFrame(health_data)
            csv = health_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ä¸‹è½½å¥åº·åº¦æŠ¥å‘Š",
                data=csv,
                file_name="network_health_report.csv",
                mime="text/csv"
            )

if __name__ == "__main__":
    main()