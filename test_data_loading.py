#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åŠ è½½åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•BigDataLoaderå’ŒDataProcessorçš„å„é¡¹åŠŸèƒ½
"""

import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from utils.data_loader import BigDataLoader, DataProcessor

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½åŠŸèƒ½"""
    print("=" * 60)
    print("æ•°æ®åŠ è½½åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–åŠ è½½å™¨
    loader = BigDataLoader()
    
    # æµ‹è¯•æ–‡ä»¶è·¯å¾„
    test_file = "e:\\AICoding\\ç”¨æˆ·æ•°æ®åˆ†æ\\åˆ‡ç‰‡.xlsx"
    
    if not os.path.exists(test_file):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        return False
    
    print(f"âœ… æµ‹è¯•æ–‡ä»¶å­˜åœ¨: {test_file}")
    
    try:
        # 1. æµ‹è¯•æ–‡ä»¶ä¿¡æ¯è·å–
        print("\n1. æµ‹è¯•æ–‡ä»¶ä¿¡æ¯è·å–...")
        info = loader.get_data_info(test_file)
        print(f"   æ–‡ä»¶å¤§å°: {info['file_size_mb']:.2f} MB")
        print(f"   é¢„ä¼°å†…å­˜: {info['estimated_memory_mb']:.2f} MB")
        print(f"   æ•°æ®å½¢çŠ¶: {info['sample_shape']}")
        print(f"   åˆ—æ•°é‡: {len(info['columns'])}")
        
        # 2. æµ‹è¯•æ ·æœ¬æ•°æ®åŠ è½½
        print("\n2. æµ‹è¯•æ ·æœ¬æ•°æ®åŠ è½½...")
        sample_df = loader.load_data_sample(test_file, sample_size=100)
        print(f"   æ ·æœ¬æ•°æ®å½¢çŠ¶: {sample_df.shape}")
        print(f"   å†…å­˜ä½¿ç”¨: {sample_df.memory_usage(deep=True).sum() / 1024:.2f} KB")
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        print(f"   ç¼ºå¤±å€¼æ•°é‡: {sample_df.isnull().sum().sum()}")
        print(f"   é‡å¤è¡Œæ•°é‡: {sample_df.duplicated().sum()}")
        
        # 3. æµ‹è¯•æ•°æ®é¢„å¤„ç†
        print("\n3. æµ‹è¯•æ•°æ®é¢„å¤„ç†...")
        processed_df = DataProcessor.preprocess_data(sample_df.copy())
        print(f"   é¢„å¤„ç†åå½¢çŠ¶: {processed_df.shape}")
        print(f"   é¢„å¤„ç†åç¼ºå¤±å€¼: {processed_df.isnull().sum().sum()}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ— ç©·å¤§å€¼
        numeric_cols = processed_df.select_dtypes(include=[np.number]).columns
        inf_count = 0
        for col in numeric_cols:
            inf_count += np.isinf(processed_df[col]).sum()
        print(f"   æ— ç©·å¤§å€¼æ•°é‡: {inf_count}")
        
        # 4. æµ‹è¯•åˆ†å—åŠ è½½ï¼ˆå°è§„æ¨¡æµ‹è¯•ï¼‰
        print("\n4. æµ‹è¯•åˆ†å—åŠ è½½...")
        chunk_count = 0
        total_rows = 0
        for chunk in loader.load_data_chunked(test_file, chunk_size=50):
            chunk_count += 1
            total_rows += len(chunk)
            if chunk_count >= 3:  # åªæµ‹è¯•å‰3ä¸ªå—
                break
        print(f"   æµ‹è¯•äº† {chunk_count} ä¸ªæ•°æ®å—")
        print(f"   æ€»è¡Œæ•°: {total_rows}")
        
        # 5. æµ‹è¯•ç”¨æˆ·èšåˆåŠŸèƒ½
        print("\n5. æµ‹è¯•ç”¨æˆ·èšåˆåŠŸèƒ½...")
        if 'ç”¨æˆ·ID' in sample_df.columns:
            user_agg = DataProcessor.aggregate_by_user(sample_df)
            print(f"   èšåˆåç”¨æˆ·æ•°: {len(user_agg)}")
            print(f"   èšåˆååˆ—æ•°: {user_agg.shape[1]}")
        else:
            print("   è·³è¿‡ç”¨æˆ·èšåˆæµ‹è¯•ï¼ˆæ— ç”¨æˆ·IDåˆ—ï¼‰")
        
        # 6. æµ‹è¯•æ—¶é—´ç‰¹å¾æå–
        print("\n6. æµ‹è¯•æ—¶é—´ç‰¹å¾æå–...")
        if 'å‘å¸ƒæ—¶é—´' in sample_df.columns:
            time_features = DataProcessor.extract_time_features(sample_df)
            print(f"   æ—¶é—´ç‰¹å¾æå–ååˆ—æ•°: {time_features.shape[1]}")
            new_cols = set(time_features.columns) - set(sample_df.columns)
            print(f"   æ–°å¢æ—¶é—´ç‰¹å¾: {list(new_cols)}")
        else:
            print("   è·³è¿‡æ—¶é—´ç‰¹å¾æµ‹è¯•ï¼ˆæ— å‘å¸ƒæ—¶é—´åˆ—ï¼‰")
        
        # 7. æµ‹è¯•æ´»è·ƒåº¦è¯„åˆ†
        print("\n7. æµ‹è¯•æ´»è·ƒåº¦è¯„åˆ†...")
        activity_df = DataProcessor.calculate_user_activity_score(sample_df)
        if 'activity_score' in activity_df.columns:
            print(f"   æ´»è·ƒåº¦è¯„åˆ†èŒƒå›´: {activity_df['activity_score'].min():.2f} - {activity_df['activity_score'].max():.2f}")
            print(f"   å¹³å‡æ´»è·ƒåº¦: {activity_df['activity_score'].mean():.2f}")
        else:
            print("   æ´»è·ƒåº¦è¯„åˆ†è®¡ç®—å¤±è´¥")
        
        print("\nâœ… æ‰€æœ‰æ•°æ®åŠ è½½åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\n" + "=" * 60)
    print("é”™è¯¯å¤„ç†æµ‹è¯•")
    print("=" * 60)
    
    loader = BigDataLoader()
    
    # æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶
    print("\n1. æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶...")
    try:
        loader.load_data_sample("ä¸å­˜åœ¨çš„æ–‡ä»¶.xlsx")
        print("   âŒ åº”è¯¥æŠ›å‡ºå¼‚å¸¸ä½†æ²¡æœ‰")
        return False
    except Exception as e:
        print(f"   âœ… æ­£ç¡®å¤„ç†äº†æ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯: {type(e).__name__}")
    
    # æµ‹è¯•ç©ºæ•°æ®å¤„ç†
    print("\n2. æµ‹è¯•ç©ºæ•°æ®å¤„ç†...")
    try:
        empty_df = pd.DataFrame()
        processed = DataProcessor.preprocess_data(empty_df)
        print(f"   âœ… ç©ºæ•°æ®å¤„ç†æˆåŠŸï¼Œç»“æœå½¢çŠ¶: {processed.shape}")
    except Exception as e:
        print(f"   âŒ ç©ºæ•°æ®å¤„ç†å¤±è´¥: {str(e)}")
        return False
    
    # æµ‹è¯•åŒ…å«å¼‚å¸¸å€¼çš„æ•°æ®
    print("\n3. æµ‹è¯•å¼‚å¸¸å€¼å¤„ç†...")
    try:
        # åˆ›å»ºåŒ…å«å¼‚å¸¸å€¼çš„æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'ç”¨æˆ·ID': [1, 2, 3, 4, 5],
            'ç²‰ä¸æ•°': [100, 200, np.inf, 300, -np.inf],
            'å…³æ³¨æ•°': [50, np.nan, 75, 100, 125],
            'æ€§åˆ«': ['ç”·', 'å¥³', None, 'ç”·', 'å¥³']
        })
        
        processed = DataProcessor.preprocess_data(test_data)
        
        # æ£€æŸ¥æ— ç©·å¤§å€¼æ˜¯å¦è¢«å¤„ç†
        inf_count = np.isinf(processed.select_dtypes(include=[np.number])).sum().sum()
        print(f"   âœ… å¼‚å¸¸å€¼å¤„ç†æˆåŠŸï¼Œå‰©ä½™æ— ç©·å¤§å€¼: {inf_count}")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼æ˜¯å¦è¢«å¤„ç†
        null_count = processed.isnull().sum().sum()
        print(f"   âœ… ç¼ºå¤±å€¼å¤„ç†æˆåŠŸï¼Œå‰©ä½™ç¼ºå¤±å€¼: {null_count}")
        
    except Exception as e:
        print(f"   âŒ å¼‚å¸¸å€¼å¤„ç†å¤±è´¥: {str(e)}")
        return False
    
    print("\nâœ… æ‰€æœ‰é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡ï¼")
    return True

if __name__ == "__main__":
    print("å¼€å§‹æ•°æ®åŠ è½½åŠŸèƒ½æµ‹è¯•...\n")
    
    # è¿è¡Œæµ‹è¯•
    test1_passed = test_data_loading()
    test2_passed = test_error_handling()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    if test1_passed and test2_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®åŠ è½½åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½ã€‚")
        if not test1_passed:
            print("   - æ•°æ®åŠ è½½åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        if not test2_passed:
            print("   - é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥")